{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d97eb5b1",
   "metadata": {},
   "source": [
    "# RAG 시스템 보기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed45488e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sehan/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터스토어 로드 중\n",
      "검색기 로드 중\n",
      "검색기 로드 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:50<00:00, 10.07s/it]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from retrieval import load_vectorstore_retriever_embeddings, rag\n",
    "from model import llm_load\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1. 벡터스토어 로드\n",
    "vectorstore, retriever, embeddings = load_vectorstore_retriever_embeddings(\"RAG/vectorDB\")\n",
    "\n",
    "# 2. LLM 한 번만 로드 (재사용)\n",
    "llm = llm_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9392082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #3. test 데이터셋 가져오기\n",
    "with open(\"datasets/popqa_dataset/qa_dataset.json\", \"r\") as f:\n",
    "    pop_qa = json.load(f)\n",
    "\n",
    "with open(\"datasets/nq_dataset/qa_dataset.json\", \"r\") as f:\n",
    "    nq_qa = json.load(f)\n",
    "\n",
    "with open(\"datasets/triviaqa_dataset/qa_dataset.json\", \"r\") as f:\n",
    "    trivia_qa = json.load(f)\n",
    "\n",
    "with open(\"datasets/bioasq_dataset/qa_dataset.json\", \"r\") as f:\n",
    "    bioasq_qa = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349fb9d7",
   "metadata": {},
   "source": [
    "### 테스트 데이터셋 랜덤 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9997fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from set_data import extract_random_qa\n",
    "\n",
    "pop_qa_sampled = extract_random_qa(pop_qa, num_qa=260)\n",
    "nq_qa_sampled = extract_random_qa(nq_qa, num_qa=260)\n",
    "trivia_qa_sampled = extract_random_qa(trivia_qa, num_qa = 261)\n",
    "bioasq_qa_sampled = extract_random_qa(bioasq_qa, num_qa=261)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2c1a9e",
   "metadata": {},
   "source": [
    "### 최종 테스트 데이터셋 만들기 - 계속해서 바뀌니 주의할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b22abe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "total_sampled = pop_qa_sampled + nq_qa_sampled + trivia_qa_sampled + bioasq_qa_sampled\n",
    "\n",
    "for idx, item in enumerate(total_sampled):\n",
    "    item[\"ids\"] = str(idx)\n",
    "    if \"idx\" in item:\n",
    "        del item[\"idx\"]\n",
    "\n",
    "if not os.path.exists(\"datasets/total_qa_sampled\"):\n",
    "    os.makedirs(\"datasets/total_qa_sampled\")\n",
    "\n",
    "\n",
    "with open(\"datasets/total_qa_sampled/qa_dataset.json\", \"w\") as f:\n",
    "    json.dump(total_sampled, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "207481e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('datasets/total_qa_sampled/qa_dataset.json', \"r\") as f:\n",
    "    total_sampled = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd5540c",
   "metadata": {},
   "source": [
    "### 역으로 QA 데이터셋을 만들어야겠는데"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aab83e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': \"What is Meyer Lutz's occupation?\", 'answers': \" Meyer Lutz's occupation is a German-born British composer and conductor.\", 'ground_truth': ['composer'], 'docs': [{'page_content': 'Meyer Lutz: 3 Later years           2 Selected works         3 Notes         4 References         5 External links                   Toggle the table of contents        Meyer Lutz    4 languages     CatalàEspañolمصرىРусский  Edit links            ArticleTalk      English                  ReadEditView history        Tools      Tools move to sidebar hide    \\t\\tActions \\t   ReadEditView history      \\t\\tGeneral \\t   What links hereRelated changesUpload filePermanent linkPage informationCite this pageGet shortened URLDownload QR code      \\t\\tPrint/export \\t   Download as PDFPrintable version      \\t\\tIn other projects \\t   Wikimedia CommonsWikidata item                       Appearance move to sidebar hide           From Wikipedia, the free encyclopedia    German-born British composer and conductor   Lutz in 1894 Wilhelm Meyer Lutz (19 May 1829 – 31 January 1903) was a German-born British composer and conductor who is best known for light music, musical theatre and burlesques of well-known works.'}, {'page_content': 'Meyer Lutz: Meyer LutzSearch⌘KToggle themeEdits HistoryToggle themeSearch⌘KHomeMeyer LutzMeyer LutzEarly life and educationCareerPersonal lifeWorksLegacyReferencesFact-checked by Grok 2 weeks agoMeyer LutzWilhelm Meyer Lutz (1829–1903) was a German-born British composer and conductor best known for his extensive work in light music, musical theatre, and burlesque productions during the Victorian era.'}, {'page_content': 'Meyer Lutz - LUX: male. Occupation/Role. Composers · Conductors (Music) · Organists · Arrangers (Musicians) · Book editors. Nationality. British · German. Web Pages. https://en.'}, {'page_content': 'Wilhelm Meyer Lutz: He also conducted theater and classical concerts, and composed operas, opera-bouffes, burlesques and cantatas.'}, {'page_content': 'Lutz Meyer-Goßner: Lutz Meyer-Goßner - Wikipedia                            Jump to content        Main menu      Main menu move to sidebar hide    \\t\\tNavigation \\t   Main pageContentsCurrent eventsRandom articleAbout WikipediaContact us      \\t\\tContribute \\t   HelpLearn to editCommunity portalRecent changesUpload fileSpecial pages                    Search            Search                       Appearance                 Donate  Create account  Log in         Personal tools      Donate Create account Log in                             Contents move to sidebar hide     (Top)      1 Selected works         2 Awards         3 Notes         4 External links                   Toggle the table of contents        Lutz Meyer-Goßner    2 languages     Deutschمصرى  Edit links            ArticleTalk      English                  ReadEditView history        Tools      Tools move to sidebar hide    \\t\\tActions \\t   ReadEditView history      \\t\\tGeneral \\t   What links hereRelated changesUpload filePermanent linkPage informationCite this pageGet shortened URLDownload QR code      \\t\\tPrint/export \\t   Download as PDFPrintable version      \\t\\tIn other projects \\t   Wikidata item                       Appearance move to sidebar hide           From Wikipedia, the free encyclopedia    German lawyer, jurist and law professor (born 1936)  Lutz Meyer-Goßner (born 10 July 1936) is a German lawyer, jurist and law professor.'}, {'page_content': 'Lutz Meyer: His career of more than three decades includes agency management and client service positions for leading international public relations consultancies.'}, {'page_content': 'Category:Meyer Lutz: Occupation. conductor · composer · organist · music arranger · editor. Collapse Authority file. Wikidata Q6826428 ISNI: 0000000058749082. VIAF cluster ID: ...'}, {'page_content': 'Lutz, (Wilhelm) Meyer: com       Skip to main content                    EXPLORE EXPLORE Earth and Environment History Literature and the Arts Medicine People Philosophy and Religion Places Plants and Animals Science and Technology Social Sciences and the Law Sports and Everyday Life Additional References Articles Daily        Arts  Dictionaries thesauruses pictures and press releases  Lutz, (Wilhelm) Meyer Lutz, (Wilhelm) Meyer gale views  updated              Lutz, (Wilhelm) MeyerLutz, (Wilhelm) Meyer, German-born English organist, conductor, and composer; b.'}, {'page_content': 'Mourning for Dr. Lutz Meyer - German Interdisciplinary ...: His career as a pediatric surgeon took him from Hanover to Berlin in 1995.'}, {'page_content': 'Faust Up to Date (Lutz, Meyer): Work Title, Faust Up to Date. Alternative. Title, Opera Burlesque in Two Acts. Composer, Lutz, Meyer. Internal Reference NumberInternal Ref. No. IML 2.'}]}\n",
      "{'question': \"What is John Barnes's occupation?\", 'answers': ' John Barnes is a former professional football player and manager.', 'ground_truth': ['monk', 'monks'], 'docs': [{'page_content': 'John Barnes: 81\\xa0m)[2]Position Left wingerYouth career Stowe Boys ClubSenior career*Years Team Apps (Gls)1980–1981 Sudbury Court  1981–1987 Watford 233 (65)1987–1997 Liverpool 314 (84)1997–1999 Newcastle United 27 (6)1999 Charlton Athletic 12 (0)Total  586 (155)International career1982–1983 England U21 3 (0)1983–1995[3] England 79 (10)Managerial career1999–2000 Celtic2008–2009 Jamaica2009 Tranmere Rovers * Club domestic league appearances and goals John Charles Bryan Barnes MBE (born 7 November 1963) is a former professional football player and manager.'}, {'page_content': \"John Barnes: John Barnes - IMDb    MenuMoviesRelease calendarTop 250 moviesMost popular moviesBrowse movies by genreTop box officeShowtimes & ticketsMovie newsIndia movie spotlightTV showsWhat's on TV & streamingTop 250 TV showsMost popular TV showsBrowse TV shows by genreTV newsWatchWhat to watchLatest trailersIMDb OriginalsIMDb PicksIMDb SpotlightFamily entertainment guideIMDb PodcastsAwards & eventsOscarsGolden Globe AwardsSundance Film FestivalMost AnticipatedCelebrity PhotosSTARmeter AwardsAwards CentralFestival CentralAll eventsCelebsBorn todayMost popular celebsCelebrity newsCommunityHelp centerContributor zonePollsFor industry professionalsLanguageEnglish (United States)LanguageFully supportedEnglish (United States)Partially supportedFrançais (Canada)Français (France)Deutsch (Deutschland)हिंदी (भारत)Italiano (Italia)Português (Brasil)Español (España)Español (México)AllAllWatchlistSign inENFully supportedEnglish (United States)Partially supportedFrançais (Canada)Français (France)Deutsch (Deutschland)हिंदी (भारत)Italiano (Italia)Português (Brasil)Español (España)Español (México)Use appBiographyAwardsTriviaFAQIMDbProAll topicsJohn Barnes(V)ActorProducerSoundtrackIMDbProStarmeterSee rankPlay trailer2:05Kenny (2017)1 Video1 PhotoConsidered a legend of English football, especially by Liverpool fans, John Barnes was born in Jamaica and moved to England aged 12.\"}, {'page_content': 'John Barnes - Player profile - Transfermarkt: John Barnes ➤ former footballer from England ➤ Left Midfield ➤ last club: Charlton Athletic ➤ * Nov 7, 1963 in Kingston, Jamaica.'}, {'page_content': 'John Barnes | Who Wants To Be A Millionaire Wiki - Fandom: John Charles Bryan Barnes MBE (born 7 November 1963) is a Jamaican-born English international former professional footballer and manager.'}, {'page_content': 'John Barnes | Booking Agent: John Barnes | Booking Agent | MN2S                                          Booking   Talent   Speakers   Live   DJs     For Brands   For Talent   For labels   LABEL SERVICES   GET YOUR MUSIC HEARD     Enquire Now                   ×                     TALENT SEARCH         CONTACT          ROSTER           Talent     Live     DJ     Speakers       OUR SERVICES           Talent Agency     Label Services     PR Agency     Influencer Marketing     Video Production & Creative Services    Product Licensing        RESOURCES        NEWS            ABOUT            For Brands            For Talent            For Labels             ROSTER            Talent     Live     DJ     Speakers          RESOURCES        NEWS                         TALENT SEARCH         OUR SERVICES           Talent Agency     Label Services     PR Agency     Influencer Marketing     Video Production & Creative Services    Product Licensing       ABOUT          CONTACT                    John Barnes          Football/Soccer            United Kingdom      John Barnes       Football/Soccer            United Kingdom              HomeBookingsTalent   John Barnes “Retired Jamaican born English footballer John Barnes is a cherished sports personality available for broadcasting opportunities, TV and personal appearances as well as after dinner speaking opportunities.'}, {'page_content': 'John Barnes Profile 2024 | Net Worth, Background, Early ...: John Barnes is a former professional football player and manager who last served as a manager in 2009 for the English fourth-division club Tranmere Rovers.'}, {'page_content': 'Football Legend and Anti-Racism Speaker John Barnes MBE ...: Presenters    Awards Hosts Broadcasters Commercial Actors Conference Facilitators Corporate Video Presenters Exhibition Hosts Female Presenters Home Studio Presenters International Presenters Live Event Hosts Male Presenters TV Presenters Virtual Presenters   Search Shortlist\\r  0   Blog            Contact Us        \\r \\t\\t\\t\\t\\r  \\r   \\r \\t\\t`\\t                     \\r                               Great British Presenters   Search My Shortlist Contact Presenters   Remote Presenters Conference Facilitators Female TV Presenters Male TV Presenters News Broadcasters Trade Show Presenters TV Presenters Video Presenters    Blog Podcast         BACK TO SEARCH                 John Barnes MBE John Barnes is widely regarded as one of the top club players in the world.'}, {'page_content': 'John Barnes: John Barnes - Life Science Access Academy                                                      Search   × Search LSA   Search for:          Contact Us/Join    Login     Member Login  Contact Us/Join                0203 916 5409      The UK’s leading training platform for the Life Science sector    About Meet the TeamTraining ResourcesMasterclasses Upcoming MasterclassesPast MasterclassesBespoke Training Become an AI Life Science Superhero!Bespoke TrainingPerformPharmaceutical Industry Diploma 2025Science of Storytelling DiplomaCompliance ABPI Code Training 2024ABPI Distance Learning ProgrammeClarke’s Code CompanionLife Science Codes of PracticeSignatory TrainingMSLAOur ExpertsContact Us        Home Meet the TeamTraining ResourcesUpcoming MasterclassesPast MasterclassesBecome an AI Life Science Superhero!Bespoke TrainingPerformPharmaceutical Industry Diploma 2025Science of Storytelling DiplomaABPI Code Training 2024ABPI Distance Learning ProgrammeClarke’s Code CompanionLife Science Codes of PracticeSignatory TrainingMSLAOur ExpertsContact Us         Back to Experts John Barnes Former professional footballer         John Barnes is a former professional footballer who is regarded as one of Liverpool and England’s greatest-ever players.'}, {'page_content': 'John Barnes (author): Louis (BA)University of Montana (MA)University of Pittsburgh (PhD)GenreScience fiction John Barnes (born 1957) is an American science fiction author.'}, {'page_content': 'Liverpool career stats for John Barnes: Barnes became the latest in a long line of ex-Liverpool players to work in the media covering football, in his case with Channel Five.'}]}\n",
      "{'question': \"What is Gerard Kennedy's occupation?\", 'answers': \" Gerard Kennedy's occupation is an actor.\", 'ground_truth': ['actor', 'actress', 'actors', 'actresses'], 'docs': [{'page_content': 'Gerard Kennedy (actor): 2 Television           5 Awards         6 References         7 External links                   Toggle the table of contents        Gerard Kennedy (actor)    7 languages     AfrikaansالعربيةDeutschEspañolفارسی한국어مصرى  Edit links            ArticleTalk      English                  ReadEditView history        Tools      Tools move to sidebar hide    \\t\\tActions \\t   ReadEditView history      \\t\\tGeneral \\t   What links hereRelated changesUpload filePermanent linkPage informationCite this pageGet shortened URLDownload QR code      \\t\\tPrint/export \\t   Download as PDFPrintable version      \\t\\tIn other projects \\t   Wikidata item                      Appearance move to sidebar hide           From Wikipedia, the free encyclopedia    Australian actor (1932–2025)   Gerard KennedyBorn(1932-03-08)8 March 1932Perth, Western Australia, AustraliaDied21 April 2025(2025-04-21) (aged\\xa093)Gosford, New South Wales, AustraliaOccupationActorYears\\xa0active1965–2015Known\\xa0forHunter, Division 4Notable workHomicidePrisonerAgainst the WindThe Flying DoctorsAwardsGold Logies × 2Silver Logies × 3Penguin Awards × 3Australian Television and Film Award Gerard Kennedy (8 March 1932 – 21 April 2025) was an Australian double Gold Logie award-winning actor.'}, {'page_content': \"Gerard Kennedy(1932-2025): Gerard Kennedy. Actor: Division 4. Once described early in his career as Australia's version of 1950's Hollywood action star Jeff Chandler, ...\"}, {'page_content': 'Gerard Kennedy Movies and Shows: â\\x80\\x8eGerard Kennedy Movies and Shows - Apple TV                                                           Sign In             Gerard Kennedy  Gerard Kennedy (8 March 1932 â\\x80\\x93 21 April 2025) was an Australian double Gold Logie award-winning actor.'}, {'page_content': 'Gold Logie winner Gerard Kennedy dies aged 93: (Getty Images: Hamish Blair)In short:Australian television star and two-time Gold Logie award winner Gerard Kennedy has died aged 93.'}, {'page_content': \"Gerard Kennedy - Biography: Gerard Kennedy. Actor: Division 4. Once described early in his career as Australia's version of 1950's Hollywood action star Jeff Chandler, ...\"}, {'page_content': 'Gerard Kennedy - Prisoner Cell Block H Wiki - Fandom: Gerard Kennedy (born 8 March 1932- April 2025) was an Australian double Gold Logie award-winning actor, best known for his roles in early television series.'}, {'page_content': 'Born in Perth in 1932 Gerard Kennedy is one of my ...: Gerard Kennedy (8 March 1932 – 21 April 2025) was an Australian double Gold Logie award-winning actor. Kennedy started his career in theatre, ...'}, {'page_content': 'Gerard Kennedy: Gerard Kennedy (born 8 March 1932) is an Australian double Gold Logie award-winning former actor, best known for his roles in early television series, in particular the espionage series including Hunter and the police procedural Division 4.'}, {'page_content': 'Obituary: Gerard Kennedy: He went on to various jobs including store man, wood cutter, telephone mechanic, taxi driver and bus conductor before joining amateur theatre in Brisbane and working as a set designer at QTQ9.'}, {'page_content': 'Gerry Kennedy: Gerry KennedySearch⌘KToggle themeEdits HistoryToggle themeSearch⌘KHomeGerry KennedyGerry KennedyEarly lifeClub careerInter-county careerHonoursReferencesFact-checked by Grok 2 weeks agoGerry KennedyGerry Kennedy (8 March 1932 – 21 April 2025), born Gerard Kennedy, was an Australian actor celebrated for his commanding presence and versatile performances in television and film over five decades.'}]}\n",
      "{'question': \"What is Giora Godik's occupation?\", 'answers': \" Giora Godik's occupation was a theater producer and impresario.\", 'ground_truth': ['impresario', 'Talent Manager'], 'docs': [{'page_content': 'Giora Godik: 2 Godik Theater           2 Controversy         3 Collapse         4 See also         5 References         6 External links                   Toggle the table of contents        Giora Godik    2 languages     עבריתمصرى  Edit links            ArticleTalk      English                  ReadEditView history        Tools      Tools move to sidebar hide    \\t\\tActions \\t   ReadEditView history      \\t\\tGeneral \\t   What links hereRelated changesUpload filePermanent linkPage informationCite this pageGet shortened URLDownload QR code      \\t\\tPrint/export \\t   Download as PDFPrintable version      \\t\\tIn other projects \\t   Wikimedia CommonsWikidata item                       Appearance move to sidebar hide           From Wikipedia, the free encyclopedia    Theater producer and impresario Giora Godik Giora Godik (Hebrew: גיורא גודיק; 1921–1977) was a Polish-born Jewish Israeli theater producer and impresario, famous for bringing musical comedies to Israel.'}, {'page_content': \"(PDF) Giora Godik: The 'Showporter' Turned Artistic Producer: 1057/978-1-137-43308-4_27visibility…description9 pagesdescriptionSee full PDFdownloadDownload PDF  bookmarkSave to LibraryshareSharecloseSign up for access to the world's latest researchSign up for freearrow_forwardcheckGet notified about relevant paperscheckSave papers to use in your researchcheckJoin the discussion with peerscheckTrack your impactAbstractAta Ohev at Yaffo!' (You love Yaffo!) Rosa from the original Israeli musical Kazablan sings.\"}, {'page_content': 'Godik, Giora: GODIK, GIORA (1918–1977), Israeli impressario. Born in Warsaw, Godik reached Palestine during World War ii, and later established himself as manager of soloists ...'}, {'page_content': 'Waiting for Godik: Waiting for GodikSearch⌘KToggle themeEdits HistoryToggle themeSearch⌘KHomeWaiting for GodikWaiting for GodikSubjectProductionRelease and ReceptionReferencesFact-checked by Grok 2 weeks agoWaiting for GodikWaiting for Godik is a 2007 Israeli documentary film written and directed by Ari Davidovich that chronicles the rise and fall of Giora Godik, a prominent theater producer and impresario known as the \"King of Musicals\" in Israel.'}, {'page_content': 'American Musicals in 1960s Israel: From West Side Story ...: Since the early years of the decade, the Broadway musical colonized the Israeli stage largely through Giora Godik’s lavish productions.'}, {'page_content': 'Waiting for Godik: Waiting for Godik - Wikipedia                               Jump to content        Main menu      Main menu move to sidebar hide    \\t\\tNavigation \\t   Main pageContentsCurrent eventsRandom articleAbout WikipediaContact us      \\t\\tContribute \\t   HelpLearn to editCommunity portalRecent changesUpload fileSpecial pages                    Search            Search                       Appearance                 Donate  Create account  Log in         Personal tools      Donate Create account Log in                             Contents move to sidebar hide     (Top)      1 Subject         2 Production         3 Awards, screenings, and response         4 References         5 External links                   Toggle the table of contents        Waiting for Godik    1 language     עברית  Edit links            ArticleTalk      English                  ReadEditView history        Tools      Tools move to sidebar hide    \\t\\tActions \\t   ReadEditView history      \\t\\tGeneral \\t   What links hereRelated changesUpload filePermanent linkPage informationCite this pageGet shortened URLDownload QR code      \\t\\tPrint/export \\t   Download as PDFPrintable version      \\t\\tIn other projects \\t   Wikidata item                       Appearance move to sidebar hide           From Wikipedia, the free encyclopedia    2007 Israeli filmWaiting for ГодикTheatrical release posterDirected byAri DavidovichWritten byDavid DavidovichProduced byAmir HarelProductioncompanyLama ProductionsDistributed bySecond Television and Radio AuthorityRelease date July\\xa010,\\xa02007\\xa0(2007-07-10) (Jerusalem Film Festival) Running time60 minutesCountryIsraelLanguageHebrew Waiting for Godik is a 2007 documentary written and directed by Ari Davidovich, chronicling the rise and fall of the Israeli theater producer and impresario Giora Godik.'}, {'page_content': 'Giora Godik - Biography Central: His career as an impresario—a role that involves the promotion, organization, and production of artistic events—was characterized by innovative programming, a keen eye for talent, and a dedication to elevating Israeli arts to international standards.'}, {'page_content': \"A 'Fiddler' In Yiddish — The Way It Ought To Be: ” Image by Getty Images The production was the brainstorm of Giora Godik, the flamboyant, Polish-born impresario famous for bringing lavish American-style musicals to the Israeli stage.\"}, {'page_content': 'Movie/TV Series, Release date between 2007-01-01 and ...: 7\\xa0(17)RateMark as watchedWaiting for Godik, a musical documentary, tells the story of the rise and fall of the Israeli King of Musicals, legendary producer and impresario Giora Godik.'}, {'page_content': \"INFORMATION: Miss Molly Picon, the American-Yiddish actress and musical star, is in Tel Aviv to pre- pare for the leading part in Giora Godik's. IsraeU production of the ...\"}]}\n",
      "{'question': \"What is Toni Jennings's occupation?\", 'answers': \" Toni Jennings's occupation is a teacher.\", 'ground_truth': ['politician', 'political leader', 'political figure', 'polit.', 'pol'], 'docs': [{'page_content': 'Toni Jennings: Toni Jennings | The Children\\'s Movement of Florida                      Skip to main content             Top Menu   Donate    Events     Donate Button  Join the movement     Main navigation   About Us   show submenu for \"About Us\"     About Us   The Florida Landscape   History   News   Our Founder   Staff & Board   Internship Program   Bring the Movement to Your Community     Business Engagement   show submenu for \"Business Engagement\"     Business Engagement   Bosses for Babies   Guide to Family-Friendly Workplaces in Florida   Local Chamber Competition   Meet Our Bosses     Community Engagement   show submenu for \"Community Engagement\"     Community Engagement   Built to Thrive   Florida Early Learning Impact Network   Parent Leadership Network   ReadingPals   The Future Call     Advocacy   show submenu for \"Advocacy\"     Advocacy   Legislative Priorities   Legislative Session 2026   All In for Early Learning    Florida’s Early Childhood Data Hub   Florida\\'s Early Learning Roadmap   KidCasting at The Capitol   Request an Advocacy Training               Board                Toni Jennings    Orlando    Bio Toni Jennings, who now chairs a family-owned construction company in Orlando, was Florida’s first woman lieutenant governor and a two-time Senate president.'}, {'page_content': 'Toni Jennings: PartyRepublicanProfessionTeacher, politician Antoinette Jennings (born May 17, 1949) is an American politician who was the 16th lieutenant governor of Florida.'}, {'page_content': 'Former Florida Lieutenant Governor Toni Jennings says ...: 07, 2013    SHARE                                  Toni Jennings began her professional career as a teacher at Killarney Elementary School in Orlando.'}, {'page_content': \"Senator Toni Jennings: Senator Toni Jennings | Florida Women's Hall of Fame                                                           NominateInducteesGallery     SearchSubmitClear        Senator Toni Jennings Perry, FL    Toni Jennings was the first Republican woman Senate President, serving two successive terms.\"}, {'page_content': \"Toni Jennings elected to FPL Group's board of directors: Jennings completed her term as Lt.\"}, {'page_content': \"Individual CRC Members: Individual CRC Members                      Commissioner Toni Jennings President's Appointment    Occupation: Senate President Birth date and place: May 17, 1949, Orlando Education: BA from Wesleyan College, 1971 Public service: Florida House of Representatives, 1976-80; President of the Florida Senate, 1980-present; Seminole County  Legislative delegation, chairman, 1990-92; Orange  County Legislative delegation, chairman, 1980-82,  1986-87, 1991-92; Metropolitan Orlando Urban  League Inc.\"}, {'page_content': \"CP Interview: Toni Jennings: During Gov. Jeb Bush's administration, she became Florida's first female lieutenant governor. She is perennially perfectly coiffed, smiling, and ...\"}, {'page_content': 'Toni Jennings: Positions, Relations and Network: Net worth:     4 M  $ as of     2025-12-30                                                       76 year                              86  connections                                                      Government                                                      Finance                                                      Consumer Durables                                                   Summary                                        Experience                                        Personal Network                                        Company connections              ProfileToni Jennings currently works at Jack Jennings & Sons, Inc.'}, {'page_content': 'Toni Jennings | Board Member: Skip to main navigation            Skip to content    About UsLeadershipCultureDiversity Inclusion BelongingMergers & AcquisitionsInvestor RelationsCareersContact Us               SolutionsProperty & CasualtyPropertyCasualtyWorker’s CompensationSuretyAviationPrivate EquityM&AExecutive LiabilityCyber RiskMultinationalAnalytics & ModelingRisk ServicesAlternative RiskCaptivesRisk SolutionsTrade CreditEmployee BenefitsBenefit Design & DeliveryFinancial Strategy & AnalyticsRegulatory & Legislative StrategyTechnology ServicesPopulation Health & Well-BeingStrategic Non-Medical SolutionsVoluntary BenefitsPharmacy BenefitsPrivate Equity/Mergers & AcquisitionsInternational BenefitsEmployer Stop LossPersonal InsuranceHomeownersAutomobilePersonal Excess LiabilityFlood and Excess FloodSpecialized CoveragesGroup ExcessMarine InsuranceIndustriesAgriculture & FoodConstructionEnergy & Power UtilityFinancial ServicesHealthcare and PharmacyHospitality & GamingManufacturingMarinePublic EntitiesReal EstateTransportationTribalAll IndustriesSpecialtiesDealer ServicesRisk SolutionsStrategic Non-Medical SolutionsTribal NationsTotal Rewards & CompensationInsightsNewsEventsCase StudiesLocations About UsLeadershipCultureDiversity Inclusion BelongingMergers & AcquisitionsInvestor RelationsCareersContact Us                                         Menu        Investor Home       News & Events        Calendar of Events       News Releases         Stock        Stock Quote & Chart       Historical Price Lookup       Investment Calculator       Analyst Coverage       Dividend History       Fundamentals         Corporate Governance        Board of Directors       Leadership       Key Documents         Financials        Quarterly Results       SEC Filings       Annual Reports       Proxy Statements         IR Resources        Investor FAQs       Email Alerts       Information Requests       Recent Reports                               Biography                                                                   Toni                                  Jennings                                        Chairman, Former Lieutenant Governor, State of Florida Jack Jennings & Sons  Independent Director  Member of the Compensation CommitteeMember of the Nominating / Corporate Governance Committee                          SolutionsProperty & CasualtyEmployee BenefitsPersonal InsuranceSpecialtiesIndustriesAbout UsOur CompanyOur CultureCareersSpecialty DistributionInsightsCase StudiesEventsNewsMedia InquiriesInvestor RelationsMergers & AcquisitionsLocations            Legal NoticesYour Privacy RightsDo Not Sell/Share/Limit DisclosureManage CookiesCookies PolicyAccessibilityCommitment to EEOMedicare DisclaimerEthics HotlineConsumer Health Data Privacy.'}, {'page_content': \"Jennings Sworn In as Florida's First Female Lt. Governor: ETORLANDO -- Toni Jennings, known as a businesswoman and legislator, reminded the hundreds of people gathered to watch her sworn in as lieutenant governor Friday that she was also a teacher.\"}]}\n"
     ]
    }
   ],
   "source": [
    "total_qa = []\n",
    "with open(\"output/output_with_base_api_rag_2.jsonl\",\"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        result = json.loads(line)\n",
    "        if i < 5:\n",
    "            print(result)\n",
    "        temp_result = {'ids' : str(i), 'question' : result['question'], 'answers' : result['ground_truth']}\n",
    "        total_qa.append(temp_result)\n",
    "\n",
    "with open(\"datasets/total_qa_sampled/qa_dataset_with_base_api_rag_2.json\", \"w\") as f:\n",
    "    json.dump(total_qa, f, ensure_ascii=False, indent=2)        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3040a2f",
   "metadata": {},
   "source": [
    "# Test with No RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7f3cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from model import llm_answer\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from prompt_template import NO_RAG_PROMPT_TEMPLATE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b40d5c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_file = \"output/output_with_no_rag.jsonl\"\n",
    "\n",
    "# PROMPT = PromptTemplate(template=NO_RAG_PROMPT_TEMPLATE, input_variables=[\"question\"])\n",
    "\n",
    "# for item in tqdm(total_sampled[:],desc=\"No RAG 처리중\"):\n",
    "#     question = item[\"question\"]\n",
    "#     prompt = PROMPT.format(question=question)\n",
    "#     answer = llm_answer(llm[0], llm[1], prompt)\n",
    "#     ground_truth = item[\"answers\"]\n",
    "\n",
    "#     result = {\n",
    "#         \"question\": question,\n",
    "#         \"answers\": answer,\n",
    "#         \"ground_truth\": ground_truth\n",
    "#     }\n",
    "\n",
    "#     with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
    "#         f.write(json.dumps(result, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# print(\"저장 완료\") # -> output/output_with_no_rag.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87839c5c",
   "metadata": {},
   "source": [
    "# Test with Wikipedia RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504f14e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAG 처리중: 100%|██████████| 1042/1042 [35:08<00:00,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# # 3. RAG 실행\n",
    "# from tqdm import tqdm\n",
    "# # 배치 설정 (수동으로 변경)\n",
    "\n",
    "# output_file = f\"output/output_with_base_rag.jsonl\"  # JSON 형식\n",
    "\n",
    "\n",
    "# for item in tqdm(total_sampled[:], desc=\"RAG 처리중\"):\n",
    "#     question = item[\"question\"]\n",
    "#     rag_output = rag(vectorstore, question, llm)\n",
    "#     ground_truth = item[\"answers\"]\n",
    "\n",
    "#     # Document 객체 → dict 변환\n",
    "#     docs_serialized = [\n",
    "#         {\"page_content\": doc.page_content, \"metadata\": doc.metadata}\n",
    "#         for doc in rag_output['source_documents']\n",
    "#     ]\n",
    "    \n",
    "#     result = {\n",
    "#         \"question\": question,\n",
    "#         \"answers\": rag_output['answer'],\n",
    "#         \"ground_truth\": ground_truth,\n",
    "#         \"docs\": docs_serialized\n",
    "#     }\n",
    "    \n",
    "#     # 한 줄씩 바로 저장 (append 모드)\n",
    "#     with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
    "#         f.write(json.dumps(result, ensure_ascii=False) + \"\\n\")\n",
    "    \n",
    "# print(f\"저장 완료\")  # -> output/output_with_base_rag.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5e89a2",
   "metadata": {},
   "source": [
    "# Test with API RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff071d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from api_rag import web_rag\n",
    "\n",
    "# total_sampled[543]\n",
    "\n",
    "# question = item[\"question\"]\n",
    "# rag_output = web_rag(question,llm)\n",
    "# ground_truth = item[\"answers\"]\n",
    "\n",
    "# # Document 객체 → dict 변환\n",
    "# docs_serialized = [\n",
    "#     {\"page_content\": doc[\"title\"] + \": \" + doc[\"paragraph\"]}\n",
    "#     for doc in rag_output['source_documents']\n",
    "# ]\n",
    "\n",
    "# result = {\n",
    "#     \"question\": question,\n",
    "#     \"answers\": rag_output['answer'],\n",
    "#     \"ground_truth\": ground_truth,\n",
    "#     \"docs\": docs_serialized\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4bc2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "API RAG 처리중: 100%|██████████| 1042/1042 [2:59:23<00:00, 10.33s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#이제 API로 평가하면 됨\n",
    "from tqdm import tqdm\n",
    "\n",
    "output_file = f\"output/output_with_base_api_rag_2.jsonl\" \n",
    "#\n",
    "from api_rag import web_rag\n",
    "\n",
    "for item in tqdm(total_sampled[:], desc=\"API RAG 처리중\"):\n",
    "    question = item[\"question\"]\n",
    "    rag_output = web_rag(question,llm)\n",
    "    ground_truth = item[\"answers\"]\n",
    "\n",
    "    # Document 객체 → dict 변환\n",
    "    docs_serialized = [\n",
    "        {\"page_content\": doc[\"title\"] + \": \" + doc[\"paragraph\"]}\n",
    "        for doc in rag_output['source_documents']\n",
    "    ]\n",
    "\n",
    "    result = {\n",
    "        \"question\": question,\n",
    "        \"answers\": rag_output['answer'],\n",
    "        \"ground_truth\": ground_truth,\n",
    "        \"docs\": docs_serialized\n",
    "    }\n",
    "\n",
    "     # 한 줄씩 바로 저장 \n",
    "    with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(result, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"저장 완료\")  # -> output/output_with_base_api_rag_2.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd1a6af",
   "metadata": {},
   "source": [
    "### 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204d6865",
   "metadata": {},
   "source": [
    "### 정확도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65ca9f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from acc_prec import load_results, calculate_accuracy_by_dataset, calculate_precision_by_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ede5191",
   "metadata": {},
   "source": [
    "#### No RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fdd10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    \"popqa\": 260,\n",
    "    \"nq\": 260, \n",
    "    \"triviaqa\": 261,\n",
    "    \"bioasq\": 261\n",
    "}\n",
    "\n",
    "results = load_results(\"output/output_with_no_rag_2.jsonl\")\n",
    "no_rag_accuracy = calculate_accuracy_by_dataset(results, dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de2217d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 데이터셋별 정확도 ===\n",
      "popqa: 26.5%\n",
      "nq: 27.3%\n",
      "triviaqa: 78.5%\n",
      "bioasq: 41.8%\n",
      "overall: 43.6%\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 데이터셋별 정확도 ===\")\n",
    "for name, accuracy in no_rag_accuracy.items():\n",
    "    print(f\"{name}: {accuracy:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6420fa3",
   "metadata": {},
   "source": [
    "#### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71783bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 크기 (순서대로: popqa, nq, triviaqa, bioasq)\n",
    "dataset_sizes = {\n",
    "    \"popqa\": 260,\n",
    "    \"nq\": 260, \n",
    "    \"triviaqa\": 261,\n",
    "    \"bioasq\": 261\n",
    "}\n",
    "\n",
    "# 결과 로드 및 정확도 계산\n",
    "results = load_results(\"output/output_with_base_api_rag_2.jsonl\")\n",
    "rag_accuracy = calculate_accuracy_by_dataset(results, dataset_sizes)\n",
    "precision_dict = calculate_precision_by_datasets(results, dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e62f73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 데이터셋별 검색 정밀도 ===\n",
      "popqa: 39.4%\n",
      "nq: 29.3%\n",
      "triviaqa: 32.3%\n",
      "bioasq: 0.0%\n",
      "overall: 25.2%\n",
      "=== 데이터셋별 정확도 ===\n",
      "popqa: 52.7%\n",
      "nq: 42.7%\n",
      "triviaqa: 77.8%\n",
      "bioasq: 33.0%\n",
      "overall: 51.5%\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 데이터셋별 검색 정밀도 ===\")\n",
    "for name, precision in precision_dict.items():\n",
    "    print(f\"{name}: {precision:.1f}%\")\n",
    "print(\"=== 데이터셋별 정확도 ===\")\n",
    "for name, accuracy in rag_accuracy.items():\n",
    "    print(f\"{name}: {accuracy:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c423e834",
   "metadata": {},
   "source": [
    "### Astute RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5524f926",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    \"popqa\": 260,\n",
    "    \"nq\": 260, \n",
    "    \"triviaqa\": 261,\n",
    "    \"bioasq\": 261\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48022436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "making Internal passage:   0%|          | 0/1042 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "making Internal passage:   4%|▍         | 42/1042 [01:03<25:16,  1.52s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m P_gen, P_con, P_ans = make_prompts(P_GEN, P_CON, P_ANS)\n\u001b[32m     19\u001b[39m E = make_external_passage()\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m I = \u001b[43mmake_internal_passage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m combine_passages = combine_passage(E,I)\n\u001b[32m     23\u001b[39m passage_source = make_passage_source(combine_passages)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/Knowledge-Conflicts/astute_rag.py:29\u001b[39m, in \u001b[36mmake_internal_passage\u001b[39m\u001b[34m(q, P_gen, M)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m each_q \u001b[38;5;129;01min\u001b[39;00m tqdm(q[:], desc = \u001b[33m\"\u001b[39m\u001b[33mmaking Internal passage\u001b[39m\u001b[33m\"\u001b[39m ):\n\u001b[32m     28\u001b[39m     P_gen_prompt = P_gen.format(question=each_q[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     I.append(\u001b[43mllm_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mM\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mP_gen_prompt\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m I\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/Knowledge-Conflicts/model.py:34\u001b[39m, in \u001b[36mllm_answer\u001b[39m\u001b[34m(model, tokenizer, prompt)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mllm_answer_gemini\u001b[39m(client, prompt, model=\u001b[33m\"\u001b[39m\u001b[33mgemini-2.0-flash\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     response = client.models.generate_content(\n\u001b[32m     35\u001b[39m         model=model,\n\u001b[32m     36\u001b[39m         contents=prompt\n\u001b[32m     37\u001b[39m     )\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.text\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/transformers/generation/utils.py:2566\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2563\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = generation_config.use_cache\n\u001b[32m   2565\u001b[39m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2566\u001b[39m result = \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2568\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2570\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2571\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2572\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2573\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2576\u001b[39m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[32m   2577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2578\u001b[39m     generation_config.return_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2579\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2580\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result.past_key_values, \u001b[33m\"\u001b[39m\u001b[33mto_legacy_cache\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2581\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/transformers/generation/utils.py:2789\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   2787\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2788\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2789\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2791\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   2792\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   2793\u001b[39m     outputs,\n\u001b[32m   2794\u001b[39m     model_kwargs,\n\u001b[32m   2795\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2796\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/transformers/utils/generic.py:918\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    920\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:433\u001b[39m, in \u001b[36mMistralForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[32m    402\u001b[39m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[32m    403\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    414\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    415\u001b[39m ) -> CausalLMOutputWithPast:\n\u001b[32m    416\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[33;03m    Example:\u001b[39;00m\n\u001b[32m    418\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    431\u001b[39m \u001b[33;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[32m    432\u001b[39m \u001b[33;03m    ```\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m     outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m     hidden_states = outputs.last_hidden_state\n\u001b[32m    445\u001b[39m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/transformers/utils/generic.py:1072\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapped_fn.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1069\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m   1071\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1072\u001b[39m     outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[32m   1074\u001b[39m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[32m   1075\u001b[39m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[32m   1076\u001b[39m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[32m   1077\u001b[39m     kwargs_without_recordable = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:369\u001b[39m, in \u001b[36mMistralModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    366\u001b[39m position_embeddings = \u001b[38;5;28mself\u001b[39m.rotary_emb(hidden_states, position_ids)\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers[: \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers]:\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     hidden_states = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.norm(hidden_states)\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[32m    381\u001b[39m     last_hidden_state=hidden_states,\n\u001b[32m    382\u001b[39m     past_key_values=past_key_values \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    383\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:246\u001b[39m, in \u001b[36mMistralDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    244\u001b[39m residual = hidden_states\n\u001b[32m    245\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.post_attention_layernorm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:47\u001b[39m, in \u001b[36mMistralMLP.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     down_proj = \u001b[38;5;28mself\u001b[39m.down_proj(\u001b[38;5;28mself\u001b[39m.act_fn(\u001b[38;5;28mself\u001b[39m.gate_proj(x)) * \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/bitsandbytes/nn/modules.py:552\u001b[39m, in \u001b[36mLinear4bit.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    550\u001b[39m inp_dtype = x.dtype\n\u001b[32m    551\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m     x = \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    554\u001b[39m bias = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias.to(\u001b[38;5;28mself\u001b[39m.compute_dtype)\n\u001b[32m    555\u001b[39m weight = \u001b[38;5;28mself\u001b[39m.weight \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(quant_state, \u001b[33m\"\u001b[39m\u001b[33mpacking_format_for_cpu\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.weight.t()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "from astute_rag import combine_passage, make_internal_passage, make_external_passage, make_prompts, make_passage_source,combine_passage, finalize_answer\n",
    "from prompt_template import P_GEN, P_CON, P_ANS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from acc_prec import load_results, calculate_accuracy_by_dataset_with_astute_rag\n",
    "\n",
    "dataset_sizes = {\n",
    "    \"popqa\": 260,\n",
    "    \"nq\": 260, \n",
    "    \"triviaqa\": 261,\n",
    "    \"bioasq\": 261\n",
    "}\n",
    "\n",
    "with open(\"datasets/total_qa_sampled/qa_dataset_with_base_api_rag_2.json\", \"r\") as f:\n",
    "    q = json.load(f)\n",
    "\n",
    "P_gen, P_con, P_ans = make_prompts(P_GEN, P_CON, P_ANS)\n",
    "\n",
    "E = make_external_passage()\n",
    "I = make_internal_passage(q, P_gen, llm)\n",
    "combine_passages = combine_passage(E,I)\n",
    "\n",
    "passage_source = make_passage_source(combine_passages)\n",
    "\n",
    "finalize_answers = []    \n",
    "for i in range(len(q)):\n",
    "    context = \"\\n\\n\".join([f\"[{j+1}]\\nsource: {doc['source']}, content: {doc['page_content']}\" for j, doc in enumerate(combine_passages[i])])\n",
    "    final_answer = finalize_answer(llm=llm, question=q[i]['question'], context_init=context, context=None)\n",
    "    finalize_answers.append(final_answer)\n",
    "\n",
    "finalize_answers = list(finalize_answers)\n",
    "\n",
    "results = load_results('./output/output_with_base_api_rag_2.jsonl')\n",
    "acc_with_astute_rag = calculate_accuracy_by_dataset_with_astute_rag(results, dataset_sizes, finalize_answers)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc124338",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_with_astute_rag = calculate_accuracy_by_dataset_with_astute_rag(results, dataset_sizes, finalize_answers)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce471a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_with_astute_rag[\"overall\"] = sum(acc_with_astute_rag.values()) / len(acc_with_astute_rag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e283f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 데이터셋별 정확도 ===\n",
      "popqa: 57.3%\n",
      "nq: 42.3%\n",
      "triviaqa: 71.3%\n",
      "bioasq: 27.6%\n",
      "overall: 49.6%\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 데이터셋별 정확도 ===\")\n",
    "for name, accuracy in acc_with_astute_rag.items():\n",
    "    print(f\"{name}: {accuracy:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1c245fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 샘플 0 ===\n",
      "질문: What is Meyer Lutz's occupation?\n",
      "정답: ['composer']\n",
      "Astute RAG 응답 (앞 500자): Based on the consolidated information from both internal and external sources, Meyer Lutz's occupation is a German-born British composer and conductor who is best known for light music, musical theatre, and burlesques of well-known works. This is consistent across multiple external sources (1, 2, 4, 7, 8) and is the most accurate and well-supported answer.\n",
      "\n",
      "<ANSWER> Composer and Conductor </ANSWER>\n",
      "\n",
      "=== 샘플 1 ===\n",
      "질문: What is John Barnes's occupation?\n",
      "정답: ['monk', 'monks']\n",
      "Astute RAG 응답 (앞 500자): Based on the consolidated information from both my own memorized documents and externally retrieved documents, John Barnes's current occupation is a television pundit and analyst. This is explicitly stated in document [11], which is from my internal memory. While other documents mention his past roles as a player and manager, none of them indicate any current occupation other than his media work.\n",
      "\n",
      "<ANSWER> John Barnes's current occupation is a television pundit and analyst. </ANSWER>\n",
      "\n",
      "=== 샘플 2 ===\n",
      "질문: What is Gerard Kennedy's occupation?\n",
      "정답: ['actor', 'actress', 'actors', 'actresses']\n",
      "Astute RAG 응답 (앞 500자): Based on the consolidated information from both internal and external sources, Gerard Kennedy's occupation is an actor. He is known for his roles in various television series and films, including Hunter, Division 4, Prisoner, Homicide, Against the Wind, and The Flying Doctors. He has won multiple awards, including two Gold Logie awards, for his acting career. There is no evidence to suggest that Gerard Kennedy is a politician, as stated in document [11].\n",
      "\n",
      "<ANSWER> Actor </ANSWER>\n",
      "\n",
      "=== 샘플 3 ===\n",
      "질문: What is Giora Godik's occupation?\n",
      "정답: ['impresario', 'Talent Manager']\n",
      "Astute RAG 응답 (앞 500자): Based on the consolidated information from both my own memorized documents and externally retrieved documents, Giora Godik's occupation is a theater producer and impresario. This is consistent across multiple sources, including [1], [2], [5], [7], and [8]. There is no mention of him being a politician in any of these sources, unlike the information provided in [11].\n",
      "\n",
      "<ANSWER> Giora Godik's occupation is a theater producer and impresario. </ANSWER>\n",
      "\n",
      "=== 샘플 4 ===\n",
      "질문: What is Toni Jennings's occupation?\n",
      "정답: ['politician', 'political leader', 'political figure', 'polit.', 'pol']\n",
      "Astute RAG 응답 (앞 500자): Based on the consolidated information from both internal and external sources, Toni Jennings's occupation can be summarized as follows:\n",
      "\n",
      "* **Political Career**: Toni Jennings served as Florida's 16th Lieutenant Governor and was the first Republican woman Senate President, serving two successive terms. She also held various other political positions such as Florida House of Representatives member, Senate President, and Seminole and Orange County Legislative delegation chair.\n",
      "* **Education**: Befo\n"
     ]
    }
   ],
   "source": [
    "# 디버깅: 첫 5개 샘플 확인\n",
    "for i in range(5):\n",
    "    print(f\"\\n=== 샘플 {i} ===\")\n",
    "    print(f\"질문: {q[i]['question']}\")\n",
    "    print(f\"정답: {results[i]['ground_truth']}\")\n",
    "    print(f\"Astute RAG 응답 (앞 500자): {finalize_answers[i][:500]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53f3785a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 수정 후 Astute RAG 정확도 ===\n",
      "popqa: 58.8%\n",
      "nq: 45.0%\n",
      "triviaqa: 82.0%\n",
      "bioasq: 41.8%\n",
      "overall: 56.9%\n"
     ]
    }
   ],
   "source": [
    "# 수정된 함수로 다시 계산\n",
    "from importlib import reload\n",
    "import acc_prec\n",
    "reload(acc_prec)\n",
    "from acc_prec import calculate_accuracy_by_dataset_with_astute_rag\n",
    "\n",
    "acc_with_astute_rag_fixed = calculate_accuracy_by_dataset_with_astute_rag(results, dataset_sizes, finalize_answers)\n",
    "acc_with_astute_rag_fixed[\"overall\"] = sum(acc_with_astute_rag_fixed.values()) / len(acc_with_astute_rag_fixed)\n",
    "\n",
    "print(\"=== 수정 후 Astute RAG 정확도 ===\")\n",
    "for name, accuracy in acc_with_astute_rag_fixed.items():\n",
    "    print(f\"{name}: {accuracy:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8217374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 기존 (버그) vs 수정 후 비교 ===\n",
      "데이터셋                 기존       수정 후 Baseline RAG\n",
      "popqa              57.3%       58.8%       52.7%\n",
      "nq                 42.3%       45.0%       42.7%\n",
      "triviaqa           71.3%       82.0%       77.8%\n",
      "bioasq             27.6%       41.8%       33.0%\n",
      "overall            49.6%       56.9%       51.5%\n"
     ]
    }
   ],
   "source": [
    "# 결과 비교\n",
    "print(\"=== 기존 (버그) vs 수정 후 비교 ===\")\n",
    "print(f\"{'데이터셋':<12} {'기존':>10} {'수정 후':>10} {'Baseline RAG':>12}\")\n",
    "for key in ['popqa', 'nq', 'triviaqa', 'bioasq', 'overall']:\n",
    "    old = acc_with_astute_rag.get(key, 0)\n",
    "    new = acc_with_astute_rag_fixed.get(key, 0)\n",
    "    baseline = rag_accuracy.get(key, 0)\n",
    "    print(f\"{key:<12} {old:>10.1f}% {new:>10.1f}% {baseline:>10.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e7c747",
   "metadata": {},
   "source": [
    "### BASELINE RAG 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ef35a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x150 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 준비\n",
    "data = {\n",
    "    'NQ': [0, 0, 0],\n",
    "    'TriviaQA': [0, 0, 0],\n",
    "    'BioASQ': [0, 0, 0],\n",
    "    'PopQA': [0, 0, 0],\n",
    "    'Overall': [0, 0, 0]\n",
    "}\n",
    "\n",
    "for key in data:\n",
    "    acc = acc_with_astute_rag[str(key).lower()]\n",
    "    data[key][2] = round(acc, 1)\n",
    "\n",
    "for key in data:\n",
    "    acc = no_rag_accuracy[str(key).lower()]\n",
    "    data[key][0] = round(acc, 1)\n",
    "    \n",
    "for key in data:\n",
    "    acc = rag_accuracy[str(key).lower()]\n",
    "    data[key][1] = round(acc, 1)  \n",
    "\n",
    "\n",
    "df = pd.DataFrame(data, index=['No RAG', 'Baseline RAG', 'Astute RAG'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 1.5))\n",
    "ax.axis('off')\n",
    "\n",
    "col_labels = [''] + list(df.columns)\n",
    "header_text = [['Mistral-Nemo (2407), 12B', '', '', '', '']]\n",
    "\n",
    "table = ax.table(\n",
    "    cellText=[[idx] + list(row) for idx, row in zip(df.index, df.values)],\n",
    "    colLabels=col_labels,\n",
    "    cellLoc='center',\n",
    "    loc='center'\n",
    ")\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1.2, 1.5)\n",
    "\n",
    "for j in range(len(col_labels)):\n",
    "    table[(0, j)].set_facecolor('#ffffff')\n",
    "    table[(0, j)].set_text_props(fontweight='bold')\n",
    "    table[(0, j)].visible_edges = 'B' \n",
    "\n",
    "for i in range(1, len(df) + 1):\n",
    "    for j in range(len(col_labels)):\n",
    "        table[(i, j)].set_facecolor('#ffffff')\n",
    "        table[(i, j)].visible_edges = 'B' if i < len(df) else ''\n",
    "\n",
    "plt.text(0.5, 0.95, 'Mistral-Nemo (2407), 12B', ha='center', va='bottom', \n",
    "         fontsize=10, fontweight='bold', transform=ax.transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knowledge_conflict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
