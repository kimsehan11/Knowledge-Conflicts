{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d97eb5b1",
   "metadata": {},
   "source": [
    "# RAG 시스템 보기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed45488e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/knowledge_conflict/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The tokenizer you are loading from './Mistral-Nemo-Instruct-2407' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
      "Loading weights: 100%|██████████| 363/363 [00:39<00:00,  9.31it/s, Materializing param=model.norm.weight]                              \n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from retrieval import load_vectorstore_retriever_embeddings, rag\n",
    "from model import llm_load\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1. 벡터스토어 로드\n",
    "\n",
    "# 2. LLM 한 번만 로드 (재사용)\n",
    "llm = llm_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9392082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #3. test 데이터셋 가져오기\n",
    "with open(\"datasets/popqa_dataset/qa_dataset.json\", \"r\") as f:\n",
    "    pop_qa = json.load(f)\n",
    "\n",
    "with open(\"datasets/nq_dataset/qa_dataset.json\", \"r\") as f:\n",
    "    nq_qa = json.load(f)\n",
    "\n",
    "with open(\"datasets/triviaqa_dataset/qa_dataset.json\", \"r\") as f:\n",
    "    trivia_qa = json.load(f)\n",
    "\n",
    "with open(\"datasets/bioasq_dataset/qa_dataset.json\", \"r\") as f:\n",
    "    bioasq_qa = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349fb9d7",
   "metadata": {},
   "source": [
    "### 테스트 데이터셋 랜덤 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9997fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from set_data import extract_random_qa\n",
    "\n",
    "pop_qa_sampled = extract_random_qa(pop_qa, num_qa=260)\n",
    "nq_qa_sampled = extract_random_qa(nq_qa, num_qa=260)\n",
    "trivia_qa_sampled = extract_random_qa(trivia_qa, num_qa = 261)\n",
    "bioasq_qa_sampled = extract_random_qa(bioasq_qa, num_qa=261)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2c1a9e",
   "metadata": {},
   "source": [
    "### 최종 테스트 데이터셋 만들기 - 계속해서 바뀌니 주의할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b22abe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "total_sampled = pop_qa_sampled + nq_qa_sampled + trivia_qa_sampled + bioasq_qa_sampled\n",
    "\n",
    "for idx, item in enumerate(total_sampled):\n",
    "    item[\"ids\"] = str(idx)\n",
    "    if \"idx\" in item:\n",
    "        del item[\"idx\"]\n",
    "\n",
    "if not os.path.exists(\"datasets/total_qa_sampled\"):\n",
    "    os.makedirs(\"datasets/total_qa_sampled\")\n",
    "\n",
    "\n",
    "with open(\"datasets/total_qa_sampled/qa_dataset.json\", \"w\") as f:\n",
    "    json.dump(total_sampled, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "207481e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('datasets/total_qa_sampled/qa_dataset.json', \"r\") as f:\n",
    "    total_sampled = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd5540c",
   "metadata": {},
   "source": [
    "### 역으로 QA 데이터셋을 만들어야겠는데"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aab83e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': \"What is J. Da Silva's occupation?\", 'answers': \" I don't know.\", 'ground_truth': ['cricket umpire', 'umpire'], 'docs': [{'page_content': 'Jay Dasilva: 70\\xa0m)[2]Position DefenderTeam informationCurrent team Coventry CityNumber 3Youth career2007–2012 Luton Town2012–2016 ChelseaSenior career*Years Team Apps (Gls)2016–2019 Chelsea 0 (0)2017 → Charlton Athletic (loan) 10 (0)2017–2018 → Charlton Athletic (loan) 38 (0)2018–2019 → Bristol City (loan) 28 (0)2019–2023 Bristol City 105 (2)2023– Coventry City 93 (0)International career‡2012–2013 England U16 4 (0)2013–2015 England U17 21 (1)2015–2016 England U18 4 (0)2016–2017 England U19 15 (0)2017–2018 England U20 6 (0)2018–2019 England U21 13 (0)2024– Wales 7 (0) * Club domestic league appearances and goals\\xa0as of 17:10, 9 September 2025 (UTC)‡ National team caps and goals as of 20:55, 18 November 2025 (UTC) Jay Rhys Dasilva (born 22 April 1998) is a professional footballer who plays as a defender/left-wing back for EFL Championship club Coventry City and the Wales national team.'}, {'page_content': 'Joshua Da Silva: 41  100s/50s 1/5 0/0 8/19 1/3  Top score 100* 9 152 103*  Catches/stumpings 121/6 1/1 221/11 41/4Source: ESPNcricinfo, 20 April 2025  Joshua Michael Da Silva (born 19 June 1998) is a Trinidadian cricketer.'}, {'page_content': 'Jay De Silva | Harry Potter Wiki | Fandom: Jay De Silva  Biographical information  Birth name Jay De Silva   Nationality British   Current residence Greater London   Gender Male   Eye colour Black   Hair colour Black   Height 5\\' 9\"    Career  In Harry Potter Death Eater   [Source]  Jay De Silva is an actor who portrays a Death Eater in Harry Potter and the Deathly Hallows: Part 1.'}, {'page_content': \"Joshua Da Silva Profile - Cricket Player West Indies: 3/20 ov, T:171) 172/3nullScheduleTableReportVideosRJW165/9SYT(20 ov, T:166) 153/8nullScheduleTableReportSeries NextLive ScoresSeriesTeamsNewsFeaturesVideosStatsEdition GLJoshua Da SilvaWest Indies|Wicketkeeper BatterCompareINTL CAREER: 2020 - 2024Most Viewed PlayersQuentin SampsonRamon SimmondsEvin LewisBrandon KingShimron HetmyerRahkeem CornwallMatthew FordeJakeem PollardAmir JangooJohnson CharlesMore LinksContracted PlayersTest CapsODI CapsT20I CapsWTest CapsWODI CapsWT20I CapsBrowse Other PlayersIrelandAllMark AdairAndy BalbirnieCurtis CampherGeorge DockrellMatthew HumphreysJosh LittleBarry McCarthyPaul StirlingHarry TectorLorcan TuckerAlphabetically sorted top ten of players who have played the most matches across formats in the last 12 monthsOverviewStatsRecordsMatchesNewsPhotosFull NameJoshua Da SilvaBornJune 19, 1998Age27y 217dNicknamesJoshBatting StyleRight hand BatFielding PositionWicketkeeperPlaying RoleWicketkeeper BatterEducationSt Mary's College, Port-of-SpainTEAMSWest IndiesTrinbago Knight RidersTrinidad & TobagoSt Kitts and Nevis PatriotsWest Indies Emerging TeamJoshua Da Silva is a keeper's keeper, combining solid glovework behind the stumps with a stoic approach to batting in front of it.\"}, {'page_content': 'Jean Silva: 3 Ultimate Fighting Championship           3 Championships and accomplishments         4 Mixed martial arts record         5 See also         6 References         7 External links                   Toggle the table of contents        Jean Silva    7 languages     العربيةEspañolFrançais日本語PortuguêsРусскийSuomi  Edit links            ArticleTalk      English                  ReadEditView history        Tools      Tools move to sidebar hide    \\t\\tActions \\t   ReadEditView history      \\t\\tGeneral \\t   What links hereRelated changesUpload filePermanent linkPage informationCite this pageGet shortened URLDownload QR code      \\t\\tPrint/export \\t   Download as PDFPrintable version      \\t\\tIn other projects \\t   Wikidata item                      Appearance move to sidebar hide           From Wikipedia, the free encyclopedia    Brazilian mixed martial artist (born 1996) Jean SilvaSilva in 2025BornJackson Jean da Silva[1] (1996-12-13) December 13, 1996 (age\\xa029)Foz do Iguaçu, Paraná, BrazilNicknameLordHeight5\\xa0ft 7\\xa0in (170\\xa0cm)Weight145\\xa0lb (66\\xa0kg; 10\\xa0st 5\\xa0lb)DivisionBantamweightFeatherweightLightweightReach69\\xa0in (175\\xa0cm)[1]Fighting out ofSão Paulo, BrazilTeamFighting NerdsYears active2016–presentMixed martial arts recordTotal19Wins16By\\xa0knockout12By\\xa0submission3By\\xa0decision1Losses3By\\xa0knockout1By\\xa0decision2 Other informationMixed martial arts record from Sherdog Jackson Jean da Silva (born December 13, 1996) is a Brazilian professional mixed martial artist.'}, {'page_content': 'Jo da Silva Facts for Kids: Quick facts for kids Dame Jo da Silva  DBE FREng FICE RDI    Born  Joanna Gabrielle da Silva  1967 (age\\xa058–59)   Alma\\xa0mater University of Cambridge (BA, MA)   Employer Arup Group   Awards Doctor of Technology (2014) Gold Medal of the Institution of Structural Engineers (2017)   Dame Joanna Gabrielle da Silva (born 1967) is a leading engineer who helps make our world better and safer.'}, {'page_content': 'Designing for natural disaster: Jo Da Silva, Engineer | V&A: In her spare time, Jo trained to be a post-disaster engineer and on her return from post-tsunami Sri Lanka in 2004, decided to focus on helping ...'}, {'page_content': 'Joao Paulo Da Silva | Overview | ATP Tour | Tennis: Official tennis player profile of Joao Paulo Da Silva on the ATP Tour. Featuring news, bio, rankings, playing activity, coach, stats, win-loss, ...'}, {'page_content': 'Joshua Da Silva Profile - ICC Ranking, Age, Career Info & ...: He is the first white player to represent the West Indies since Brendon Nash.'}, {'page_content': 'We first interviewed award-winning filmmaker Jason Da ...: We first interviewed award-winning filmmaker Jason Da Silva back in 2015 soon after his film, When I Walk was released.'}]}\n",
      "{'question': \"What is Marina Baker's occupation?\", 'answers': \" Marina Baker's occupation is a politician, journalist, children's book author.\", 'ground_truth': ['Playboy Playmate', 'Playmate'], 'docs': [{'page_content': 'Marina Baker: Find sources:\\xa0\"Marina Baker\"\\xa0–\\xa0news\\xa0· newspapers\\xa0· books\\xa0· scholar\\xa0· JSTOR (August 2014) (Learn how and when to remove this message)   Marina BakerBornMarina Augusta Baker (1967-12-08) 8 December 1967 (age\\xa058) [1]Windsor, Berkshire, EnglandOther\\xa0namesMarina PepperEducationLondon College of CommunicationAlma\\xa0materUniversity of SussexOccupationspolitician, journalist, children\\'s book authorKnown\\xa0forPlayboy Playmate for the Month of March 1987Political partyLiberal DemocratChildrenCharlie PepperBoudicca Pepper Marina Augusta Pepper (née Baker; born 8 December 1967) is an English Liberal Democrat local politician, journalist, children\\'s book author and former model and actress.'}, {'page_content': \"Marina Baker: Marina BakerSearch⌘KToggle themeEdits HistoryToggle themeSearch⌘KHomeMarina BakerMarina BakerEarly Life and BackgroundModeling CareerEntertainment and Media CareerWriting and Literary ContributionsPolitical CareerPersonal LifeReferencesFact-checked by Grok last weekMarina Baker Marina Augusta Pepper (née Baker; born 8 December 1967) is an English former glamour model and actress who gained prominence as Playboy's Playmate of the Month for March 1987, later transitioning to roles as a journalist, children's book author, and local political figure associated with environmental activism and the Liberal Democrats.\"}, {'page_content': \"Marina Baker - Age, Bio, Family: Marina Baker - Age, Bio, Family | Famous Birthdays                                                                 popular        trending        video        trivia        random                 Marina Baker            \\t\\t\\t\\t\\t\\tMovie Actress \\t\\t\\t\\t\\t     \\t\\t\\t          \\t Birthday \\t\\t\\t            December 8,    1967    Birth Sign Sagittarius   Birthplace  Berkshire,\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tEngland    Age  58 years old       #342,946 Most Popular        Boost           About  English actress, entertainer, artist, author, journalist, and former Playboy model known for being Playboy's Playmate of the Month for March 1987, for her acting in the feature film Casanova, and the short film Man from China.\"}, {'page_content': 'Marina Baker - Biographical Summaries of Notable People: Nationality: England. Ethnicity: English people. Occupations: Writer, Politician, Journalist, Nude Glamour Model, Model, Author, Actor.'}, {'page_content': 'Interview with Young Author Marina Baker: Marina is a prolific and talented writer and has already published a collection of poetry titled Sock Drawer.'}, {'page_content': \"Marina Baker: Marina Baker - Wikidata                                    Jump to content        Main menu      Main menu move to sidebar hide    \\t\\tNavigation \\t   Main pageCommunity portalProject chatCreate a new ItemRecent changesRandom ItemQuery ServiceNearbyHelpSpecial pages      \\t\\tLexicographical data \\t   Create a new LexemeRecent changesRandom Lexeme                           Search            Search           English               Appearance                 Donate  Create account  Log in         Personal tools      Donate Create account Log in                             Marina Baker (Q9029070)            ItemDiscussion      English                  ReadView history        Tools      Tools move to sidebar hide    \\t\\tActions \\t   ReadView history      \\t\\tGeneral \\t   What links hereRelated changesPermanent linkPage informationCite this pageGet shortened URLDownload QR codeConcept URI      \\t\\tPrint/export \\t   Create a bookDownload as PDFPrintable version      \\t\\tIn other projects \\t                        Appearance move to sidebar hide         From Wikidata      British politician, writer, actor and modelMarina Augusta Pepper  edit    Language Label Description Also known as    default for all languages No label defined    –        English Marina Baker British politician, writer, actor and model  Marina Augusta Pepper    Statements  instance of                human         1 reference      imported from Wikimedia project     English Wikipedia              sex or gender                female         1 reference      based on heuristic     inferred from person's given name              country of citizenship                United Kingdom         0 references         given name                Marina         1 reference      based on heuristic     inferred from person's full name              family name                Baker         1 reference      based on heuristic     inferred from person's full name              date of birth                8 December 1967         2 references      imported from Wikimedia project     Spanish Wikipedia           stated in     IMDb        IMDb ID     nm0048733        retrieved     12 July 2016              place of birth                Windsor         1 reference      imported from Wikimedia project     English Wikipedia        Wikimedia import URL     https://en.\"}, {'page_content': 'Marina Baker: Personal Info ; Known For Acting ; Known Credits 2 ; Gender Female ; Birthday December 8, 1967 (58 years old) ; Place of Birth Windsor, Berkshire, England, UK ...'}, {'page_content': 'Back - Marina Baker: She has 44 career Top 10 country albums, a record for any artist and she has 110 career-charted singles over the past 40 years. Her 49th ...'}, {'page_content': 'Marina Baker, Miss March, 1987: Turn-Offs: Fur coats, smokers, men who shave their chestsOccupation: Actress in musical \"Forever Elvis\"Favorite TV Show: Anything with good acting (i.'}, {'page_content': 'Former Playboy model, author, columnist and politician ...: Former Playboy model, author, columnist and politician Marina Baker, at home in Saltdean Stock Photo - AlamyImagesImages homepagePhotosVectorsIllustrations360° panoramic imagesImage categoriesContributor spotlightVideosVideos homepageVideo collectionsCreativeCreative homepageFresh picksEditorialEditorial homepageNewsLive NewsSportsEntertainmentArchiveArchive homepageBiographiesObituariesWorld eventsDiscoveries & launchesBlogBlog homepageNewsFeaturesSpotlightsInspirationEducationGalleriesEnterpriseEnterprise homepageEducationGamingMuseumsTrade booksTravelTV & filmAlamy APIAI TrainingBook a demoAbout usSellMake money with AlamyContributor help pageSign up as a contributorOur LicensesImage licensesVideo licensesLightboxesCartSign inHi there!LightboxesShare Alamy images with your team and customersCreate a lightbox ›All imagesAll imagesPhotographsVectorsIllustrations360° imagesVideoLive newsSearch by imageSearch for imagesSearch for stock images, vectors and videosSearch with an image file or link to find similar images···Former Playboy model, author, columnist and politician Marina Baker, at home in SaltdeanCaptions are provided by our contributors.'}]}\n",
      "{'question': \"What is Paul Hindemith's occupation?\", 'answers': ' Paul Hindemith was a German composer, teacher, violinist, violist, and conductor.', 'ground_truth': ['composer', 'concertmaster', 'principal violin', 'principal violinist', 'first chair', 'leader'], 'docs': [{'page_content': 'Paul Hindemith: Paul Hindemith was a German and American composer, music theorist, teacher, violist and conductor. He founded the Amar Quartet in 1921, touring extensively ...'}, {'page_content': 'Paul Hindemith - Music and the Holocaust - World ORT: He began his career as a conductor in 1947, having become a US citizen in 1946.'}, {'page_content': 'Paul Hindemith | German Composer & 20th Century ...: Paul Hindemith was one of the principal German composers of the first half of the 20th century and a leading musical theorist.'}, {'page_content': 'Paul Hindemith: Frankfurt, December 28, 1963\\r \\r Biography\\r Paul Hindemith was an accomplished German composer, conductor, violist, and teacher.'}, {'page_content': 'Paul Hindemith - Biography: Paul Hindemith - Biography | Deutsche GrammophonPaul Hindemith - Biography | Deutsche GrammophonSkip to main contentExplore the DG world:Label & ReleasesSTAGE+Grains MusicShopPaul HindemithENMenuPaul HindemithHomeDiscographyBiographyBiographyOne of the most important composers of the first half of the 20th century, Paul Hindemith dominated German musical life during the Weimar Republic (1919–33).'}, {'page_content': 'enigmatic composer Paul Hindemith (Oct 1995): Hindemith himself was a virtuoso on the viola and a talented player of virtually every other orchestral instrument.'}, {'page_content': 'Paul Hindemith: Paul Hindemith | Seattle Chamber Music Society                                                                                                                                    Adult and Youth Academy Applications are open, apply now!                                       Menu                                 Search          Whats On         Whats On                  Event Calendar Signature Series 2026 Winter Festival 2026 Virtual Concert Hall    Event Calendar Signature Series 2026 Winter Festival 2026 Virtual Concert Hall                     Education         Education                  Academy for Chamber Music Masterclasses Lecture Series Open Rehearsals Commissioning Club    Academy for Chamber Music Masterclasses Lecture Series Open Rehearsals Commissioning Club                     Community         Community                  String Quartet in Residence The Concert Truck Chamber Music in the Park Sight Reading Parties Azure Concerts    String Quartet in Residence The Concert Truck Chamber Music in the Park Sight Reading Parties Azure Concerts                     Give         Give                  Donate Today Ways to Give Donor Benefits Legacy Club    Donate Today Ways to Give Donor Benefits Legacy Club                     About         About                  Artistic Director Our Vision & Mission Board and Staff Careers FAQs Contact Us Artist Archive    Artistic Director Our Vision & Mission Board and Staff Careers FAQs Contact Us Artist Archive                      What’s On  Event Calendar Winter Festival 2026 Virtual Concert Hall Open Rehearsals Lecture Series Sight Reading Parties Signature Series 2026 Concerts at the Center   Education  Academy for Chamber Music Masterclasses Lecture Series Open Rehearsals Commissioning Club   Community  String Quartet in Residence The Concert Truck Chamber Music in the Park Sight Reading Parties Azure Family Concerts Chambermates   Give  Donate Today Ways to Give Donor Benefits Legacy Club   About  Artistic Director Our Vision & Mission Board and Staff Careers FAQs Contact Us Artist Archive     Hamburger Toggle Menu             Whats On                  Event Calendar Signature Series 2026 Winter Festival 2026 Virtual Concert Hall    Event Calendar Signature Series 2026 Winter Festival 2026 Virtual Concert Hall                 Education                  Academy for Chamber Music Masterclasses Lecture Series Open Rehearsals Commissioning Club    Academy for Chamber Music Masterclasses Lecture Series Open Rehearsals Commissioning Club                 Community                  String Quartet in Residence The Concert Truck Chamber Music in the Park Sight Reading Parties Azure Concerts    String Quartet in Residence The Concert Truck Chamber Music in the Park Sight Reading Parties Azure Concerts                 Give                  Donate Today Ways to Give Donor Benefits Legacy Club    Donate Today Ways to Give Donor Benefits Legacy Club                 About                  Artistic Director Our Vision & Mission Board and Staff Careers FAQs Contact Us Artist Archive    Artistic Director Our Vision & Mission Board and Staff Careers FAQs Contact Us Artist Archive                                 Get Tickets              Support SCMS                  Add Your Heading Text Here                  What’s On  Event Calendar Winter Festival 2026 Virtual Concert Hall Open Rehearsals Lecture Series Sight Reading Parties Signature Series 2026 Concerts at the Center   Education  Academy for Chamber Music Masterclasses Lecture Series Open Rehearsals Commissioning Club   Community  String Quartet in Residence The Concert Truck Chamber Music in the Park Sight Reading Parties Azure Family Concerts Chambermates   Give  Donate Today Ways to Give Donor Benefits Legacy Club   About  Artistic Director Our Vision & Mission Board and Staff Careers FAQs Contact Us Artist Archive     Hamburger Toggle Menu               Donate              Tickets                           Search                                                          1895 - 1963      Paul Hindemith     Paul Hindemith was a German composer, teacher, violinist, violist, and conductor.'}, {'page_content': 'Paul Hindemith (1895-1963) | Biography, Music & More: He was uncompromising and highly critical of Schoenberg as a teacher, theorist, and composer and thereby initiated the ongoing discussion of the role of music and the artist in contemporary society.'}, {'page_content': 'Paul Hindemith: — Fanfare                    Home  \\r                     Composers\\r                    \\r                     Artists\\r                    Catalogue    \\r                     All Titles\\r                    \\r                     Series\\r                    \\r                     Composer Cycles\\r                    \\r                     National Origins\\r                    \\r                     World Première Recordings\\r                      Media    \\r                     Video Trailers\\r                                     Paul Hindemith (1895 -  1963)   Respected as one of the most distinguished viola players of his time, Hindemith devoted the earlier part of his career to performance, first as a violinist and then as a viola player in the Amar-Hindemith Quartet, while developing his powers as a composer and his distinctive theories of harmony and of the place of the composer in society.'}, {'page_content': 'On November 16th, 1895, Composer and conductor Paul ...: Reddit - The heart of the internet                                    Skip to main content                            Open menu  Open navigation               Go to Reddit Home                 r/classicalmusic                   Get App              Get the Reddit app                Log In  Log in to Reddit           Expand user menu Open settings menu                                                                        Go to classicalmusic                     r/classicalmusic   •      BirdBurnett                           FilipinoEspañol (España)Deutsch                On November 16th, 1895, Composer and conductor Paul Hindemith is born in Hanau, German Empire.'}]}\n",
      "{'question': \"What is Ruth Harriet Louise's occupation?\", 'answers': ' Ruth Harriet Louise was a photographer.', 'ground_truth': ['photographer', 'photog', 'photographers'], 'docs': [{'page_content': \"Ruth Harriet Louise: Ruth Harriet Louise was an American photographer. She was the first woman photographer active in Hollywood, and she ran Metro-Goldwyn-Mayer's portrait ...\"}, {'page_content': 'Ruth Harriet Louise - Women Film Pioneers Project: A gifted and sensitive photographer, Ruth Harriet Louise worked for less than ten years in her chosen profession, running her own studio for three years in New ...'}, {'page_content': 'Ruth Harriet Louise Biography | Museum of Art: John Bullard Collection Shellburne Thurber: Full Circle   Upcoming Past Exhibitions Virtual Exhibitions   Learn & Explore  Events  Upcoming Events Past Events   Faculty Resources Student Resources K-12 & Homeschooler Resources General Public & Community Organization Resources   Collections  About Using the Database Collection Database   Marsden Hartley  Introduction Marsden Hartley Memorial Collection Marsden Hartley Exhibitions in the Museum The Marsden Hartley Legacy Project  Image Policies and Guidelines Legacy Grant Funding Article Artwork Submissions   Hartley Material in Bates Archives   Student Involvement  Internships Interns’ Blog Museum Podcast Assistant Education Curator of Academic and Community Programs Senior Thesis Exhibitions   Press & Publications  Press Publications Collection Highlights   Join & Support  Join Our Mailing List Friends of the Museum Bates Alumni Collectors Society Project/Program Support Planned Giving Gifts of Art          Ruth Harriet Louise (American, 1903-1940)  Louise became the first woman photographer active in the Hollywood film industry.'}, {'page_content': 'A Gallery of the Work of Ruth Harriet Louise, Photographer ...: A Gallery of the Work of Ruth Harriet Louise, Photographer & Hollywood Pioneer | Austin Film Society                                                                                   Search for:      Screenings & Events  Screenings Classes & Events 2026 Texas Film Awards Texas Film Hall Of Fame Gift Cards Film Series Calendar   Community Programs  Austin Public  About Austin Public Become a Producer Producer Portal Login Austin Public Resources Training Videos & Other Resources Watch   Classes Tours Creative Careers Production Services   Artist Development  AFS Grants  Overview AFS Grants Applications Travel Grant Past Recipients   Works-In-Progress Sponsored Films Artist Intensive Doc Intensive Filmmaker FAQs      Join & Give  Become A Member  Join or Renew Join the Impact Circle Membership FAQs Gift A Membership   Sponsorship Member Login Ways to Give Gift Cards Donate To AFS   Rentals & Facilities  Facilities  AFS Cinema Austin Public Austin Studios  About Austin Studios Contact     Production & Event Space Rentals Production Services   About  Our Story Our Mission, Vision, Values Jobs & Internships Board Of Directors  Board Of Directors Board Member Portal   Staff Annual Reports Press Filmmaker Advisory Committee Contact       Tickets Calendar Search Donate AFS Cinema Austin Public Austin Studios                     A Gallery of the Work of Ruth Harriet Louise, Photographer & Hollywood Pioneer       Greta Garbo, photographed by Ruth Harriet Louise Ruth Harriet Louise, born Ruth Goldstein on this date in 1903, came to Los Angeles at only age 22 and set up a portrait photography studio in the booming Hollywood district where, providentially, rising mogul Louis B.'}, {'page_content': 'Ruth Harriet Louise: Ruth Harriet Louise - Hundred Heroines                                                                                    Skip to main content               facebook RSS instagram email Hundred Heroines Museum  Showcase Projects Heroines Heroines Past Donate             Hit enter to search or ESC to close     Close Search                   search    Menu         Visit Exhibitions Collection Resources Youth Programme Events   search               Front PageHistorical HeroinesHPBlogLHBlog  Ruth Harriet Louise  By Del Barrett8th January 2023January 8th, 2024No Comments                                   Eleanor Boardman by Ruth Harriet Louise, courtesy of the Hundred Heroines Collection             Ruth Harriet Louise (1903-1940) First woman photographer to run the Metro-Goldwyn-Mayer portrait studio.'}, {'page_content': 'Garbo Portraits - by Ruth Harriet Louise: com     \\xa0    Garbo Portraits - by Ruth Harriet Louise         Introduction       Ruth Harriet Louise (1903-1940) was an American professional photographer.'}, {'page_content': 'When Ruth Harriet Louise was hired by MGM as chief ...: Retro Reels | When Ruth Harriet Louise was hired by MGM as chief portrait photographer in 1925, she was only 22 years old, the only woman for the Hollywood studios.'}, {'page_content': 'Ruth Harriet Louise (1903-1940) was an ... - Instagram: Louise was hired by MGM as chief portrait photographer in the summer of 1925. She was the only woman working as a portrait photographer for the ...'}, {'page_content': 'Ruth Harriet Louise: Ruth Harriet Louise - Hundred Heroines                                                                                    Skip to main content               facebook RSS instagram email Hundred Heroines Museum  Showcase Projects Heroines Heroines Past Donate             Hit enter to search or ESC to close     Close Search                   search    Menu         Visit Exhibitions Collection Resources Youth Programme Events   search               Front PageHistorical HeroinesHPBlogLHBlog  Ruth Harriet Louise  By Del Barrett8th January 2023January 8th, 2024No Comments                                   Eleanor Boardman by Ruth Harriet Louise, courtesy of the Hundred Heroines Collection             Ruth Harriet Louise (1903-1940) First woman photographer to run the Metro-Goldwyn-Mayer portrait studio.'}, {'page_content': 'Vintage: Portraits by Ruth Harriet Louise (1920s): Vintage: Portraits by Ruth Harriet Louise (1920s) | MONOVISIONS - Black & White Photography MagazineMONOVISIONS – Black & White Photography Magazine                                                                                             News  Photo Books Photo Contests Photo Exhibitions Photo Projects Features   Interviews  Alternative Process Architecture Conceptual Documentary Fashion Fine Art Landscapes Miscellaneous Nudes Photojournalism Portrait Street Surreal   Vintage  1800s 1900s 1910s 1920s XX Century Classic Films Historic City Views Glass/Plate Collections   B&W Masters  Abstract Architecture City Life Documentary Fashion Fine Art Landscapes Miscellaneous Nudes People Photojournalism Portrait Street   B&W Photo Awards Submissions    Home › Vintage › 1920s › Vintage: Portraits by Ruth Harriet Louise (1920s)      Vintage: Portraits by Ruth Harriet Louise (1920s)   1920s, Vintage     28 April 2020      \\t\\t\\t\\t\\t0 \\t\\t\\t\\t     Ruth Harriet Louise (1903 – 1940) was an American professional photographer, the first woman photographer active in Hollywood; she ran Metro-Goldwyn-Mayer’s portrait studio from 1925 to 1930.'}]}\n",
      "{'question': \"What is Sir Thomas Clarges, 3rd Baronet's occupation?\", 'answers': ' Sir Thomas Clarges, 3rd Baronet was a politician.', 'ground_truth': ['politician', 'political leader', 'political figure', 'polit.', 'pol'], 'docs': [{'page_content': 'Sir Thomas Clarges, 3rd Baronet: Sir Thomas Clarges, 3rd Baronet - Wikipedia                               Jump to content        Main menu      Main menu move to sidebar hide    \\t\\tNavigation \\t   Main pageContentsCurrent eventsRandom articleAbout WikipediaContact us      \\t\\tContribute \\t   HelpLearn to editCommunity portalRecent changesUpload fileSpecial pages                    Search            Search                       Appearance                 Donate  Create account  Log in         Personal tools      Donate Create account Log in                             Contents move to sidebar hide     (Top)      1 Notes         2 References                   Toggle the table of contents        Sir Thomas Clarges, 3rd Baronet    Add languages      Add links            ArticleTalk      English                  ReadEditView history        Tools      Tools move to sidebar hide    \\t\\tActions \\t   ReadEditView history      \\t\\tGeneral \\t   What links hereRelated changesUpload filePermanent linkPage informationCite this pageGet shortened URLDownload QR code      \\t\\tPrint/export \\t   Download as PDFPrintable version      \\t\\tIn other projects \\t   Wikidata item                      Appearance move to sidebar hide           From Wikipedia, the free encyclopedia    English politician   Annuity (Heirs of Sir Thomas Clarges) Act 1799Act of ParliamentParliament of Great BritainLong titleAn act to enable the lords commissioners of the treasury to contract with the most noble Charles duke of Richmond, for the absolute purchase of the property of the said duke, and all others interested in a certain duty of twelve pence per chaldron on coals shipped in the river Tyne to be consumed in England, and to grant a compensation for the same, by way of annuity payable out of the consolidated fund.'}, {'page_content': 'Death of a Lincoln MP Sir Thomas Clarges, 3rd Baronet ...: He was Merchant of the Staple; was several times Mayor, an Alderman; a \"Keeper of the Peace\"; and the builder of Thurland Hall, afterwards known ...'}, {'page_content': 'Dictionary of National Biography, 1885-1900/Clarges, Thomas: Clarges is commonly referred to as Dr.'}, {'page_content': \"Person Page - 22576: He succeeded as the 3rd Baronet Clarges, of St. Martin's in the Fields, co. Middlesex [E., 1674] on 19 February 1759. He matriculated at Christ Church ...\"}, {'page_content': 'Thomas Clarges: Sir Thomas Clarges (c 1618 – 4 October 1695) was an English politician who sat in the House of Commons at various times between 1656 and 1695.'}, {'page_content': 'Biography of Thomas Clarges 1618-1695: Thomas Clarges, physician to the army, created a baronet2, 1674, died 1695.'}, {'page_content': 'Sir Thomas Clarges, 4th Baronet: Sir Thomas Clarges, 4th BaronetSearch⌘KToggle themeEdits HistoryToggle themeSearch⌘KHomeSir Thomas Clarges, 4th BaronetSir Thomas Clarges, 4th BaronetEarly lifeCareer and public servicePersonal interests and estatesDeath and successionReferencesFact-checked by Grok 3 weeks agoSir Thomas Clarges, 4th Baronet Sir Thomas Clarges, 4th Baronet (c.'}, {'page_content': 'Sir Thomas Clarges, 2nd Baronet Facts for Kids: A Career in Politics\\u200b\\u200b Sir Thomas Clarges became a Member of Parliament (often called an MP). An MP is a person chosen to represent a specific ...'}, {'page_content': 'Clarges baronets: He was succeeded by his grandson, Thomas, the third Baronet, the son of Thomas Clarges.'}, {'page_content': \"St Mary-le-Strand and the Maypole: ' In the end a verdict was given for the defendant, who was only son to Sir Thomas Clarges, Knight, brother of the duchess, and who was created a baronet in 1674.\"}]}\n"
     ]
    }
   ],
   "source": [
    "total_qa = []\n",
    "with open(\"output/output_with_base_api_rag.jsonl\",\"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        result = json.loads(line)\n",
    "        if i < 5:\n",
    "            print(result)\n",
    "        temp_result = {'ids' : str(i), 'question' : result['question'], 'answers' : result['ground_truth']}\n",
    "        total_qa.append(temp_result)\n",
    "\n",
    "with open(\"datasets/total_qa_sampled/qa_dataset_with_base_api_rag.json\", \"w\") as f:\n",
    "    json.dump(total_qa, f, ensure_ascii=False, indent=2)        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3040a2f",
   "metadata": {},
   "source": [
    "# Test with No RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7f3cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from model import llm_answer\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from prompt_template import NO_RAG_PROMPT_TEMPLATE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b40d5c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_file = \"output/output_with_no_rag.jsonl\"\n",
    "\n",
    "# PROMPT = PromptTemplate(template=NO_RAG_PROMPT_TEMPLATE, input_variables=[\"question\"])\n",
    "\n",
    "# for item in tqdm(total_sampled[:],desc=\"No RAG 처리중\"):\n",
    "#     question = item[\"question\"]\n",
    "#     prompt = PROMPT.format(question=question)\n",
    "#     answer = llm_answer(llm[0], llm[1], prompt)\n",
    "#     ground_truth = item[\"answers\"]\n",
    "\n",
    "#     result = {\n",
    "#         \"question\": question,\n",
    "#         \"answers\": answer,\n",
    "#         \"ground_truth\": ground_truth\n",
    "#     }\n",
    "\n",
    "#     with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
    "#         f.write(json.dumps(result, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# print(\"저장 완료\") # -> output/output_with_no_rag.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87839c5c",
   "metadata": {},
   "source": [
    "# Test with Wikipedia RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504f14e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAG 처리중: 100%|██████████| 1042/1042 [35:08<00:00,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# # 3. RAG 실행\n",
    "# from tqdm import tqdm\n",
    "# # 배치 설정 (수동으로 변경)\n",
    "\n",
    "# output_file = f\"output/output_with_base_rag.jsonl\"  # JSON 형식\n",
    "\n",
    "\n",
    "# for item in tqdm(total_sampled[:], desc=\"RAG 처리중\"):\n",
    "#     question = item[\"question\"]\n",
    "#     rag_output = rag(vectorstore, question, llm)\n",
    "#     ground_truth = item[\"answers\"]\n",
    "\n",
    "#     # Document 객체 → dict 변환\n",
    "#     docs_serialized = [\n",
    "#         {\"page_content\": doc.page_content, \"metadata\": doc.metadata}\n",
    "#         for doc in rag_output['source_documents']\n",
    "#     ]\n",
    "    \n",
    "#     result = {\n",
    "#         \"question\": question,\n",
    "#         \"answers\": rag_output['answer'],\n",
    "#         \"ground_truth\": ground_truth,\n",
    "#         \"docs\": docs_serialized\n",
    "#     }\n",
    "    \n",
    "#     # 한 줄씩 바로 저장 (append 모드)\n",
    "#     with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
    "#         f.write(json.dumps(result, ensure_ascii=False) + \"\\n\")\n",
    "    \n",
    "# print(f\"저장 완료\")  # -> output/output_with_base_rag.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5e89a2",
   "metadata": {},
   "source": [
    "# Test with API RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4bc2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "API RAG 처리중:   0%|          | 0/210 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "API RAG 처리중:   9%|▉         | 19/210 [07:14<1:16:14, 23.95s/it]"
     ]
    }
   ],
   "source": [
    "#이제 API로 평가하면 됨\n",
    "from tqdm import tqdm\n",
    "\n",
    "output_file = f\"output/output_with_base_api_rag.jsonl\" \n",
    "#\n",
    "from api_rag import web_rag\n",
    "\n",
    "for item in tqdm(total_sampled[832:], desc=\"API RAG 처리중\"):\n",
    "    question = item[\"question\"]\n",
    "    rag_output = web_rag(question,llm, mode=\"mistral\")\n",
    "    ground_truth = item[\"answers\"]\n",
    "\n",
    "    docs_serialized = [\n",
    "        {\"page_content\": doc[\"title\"] + \": \" + doc[\"paragraph\"]}\n",
    "        for doc in rag_output['source_documents']\n",
    "    ]\n",
    "\n",
    "    result = {\n",
    "        \"question\": question,\n",
    "        \"answers\": rag_output['answer'],\n",
    "        \"ground_truth\": ground_truth,\n",
    "        \"docs\": docs_serialized\n",
    "    }\n",
    "\n",
    "     # 한 줄씩 바로 저장 \n",
    "    with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(result, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"저장 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd1a6af",
   "metadata": {},
   "source": [
    "### 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204d6865",
   "metadata": {},
   "source": [
    "### 정확도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65ca9f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from acc_prec import load_results, calculate_accuracy_by_dataset, calculate_precision_by_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ede5191",
   "metadata": {},
   "source": [
    "#### No RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96fdd10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    \"popqa\": 260,\n",
    "    \"nq\": 260, \n",
    "    \"triviaqa\": 261,\n",
    "    \"bioasq\": 261\n",
    "}\n",
    "\n",
    "results = load_results(\"output/output_with_no_rag.jsonl\")\n",
    "no_rag_accuracy = calculate_accuracy_by_dataset(results, dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9de2217d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 데이터셋별 정확도 ===\n",
      "popqa: 28.5%\n",
      "nq: 31.2%\n",
      "triviaqa: 72.8%\n",
      "bioasq: 47.9%\n",
      "overall: 45.1%\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 데이터셋별 정확도 ===\")\n",
    "for name, accuracy in no_rag_accuracy.items():\n",
    "    print(f\"{name}: {accuracy:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6420fa3",
   "metadata": {},
   "source": [
    "#### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71783bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 크기 (순서대로: popqa, nq, triviaqa, bioasq)\n",
    "dataset_sizes = {\n",
    "    \"popqa\": 260,\n",
    "    \"nq\": 260, \n",
    "    \"triviaqa\": 261,\n",
    "    \"bioasq\": 261\n",
    "}\n",
    "\n",
    "# 결과 로드 및 정확도 계산\n",
    "results = load_results(\"output/output_with_base_api_rag.jsonl\")\n",
    "rag_accuracy = calculate_accuracy_by_dataset(results, dataset_sizes)\n",
    "precision_dict = calculate_precision_by_datasets(results, dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e62f73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 데이터셋별 검색 정밀도 ===\n",
      "popqa: 39.9%\n",
      "nq: 28.2%\n",
      "triviaqa: 70.0%\n",
      "bioasq: 7.7%\n",
      "overall: 36.4%\n",
      "=== 데이터셋별 정확도 ===\n",
      "popqa: 54.6%\n",
      "nq: 41.9%\n",
      "triviaqa: 85.8%\n",
      "bioasq: 42.5%\n",
      "overall: 56.2%\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 데이터셋별 검색 정밀도 ===\")\n",
    "for name, precision in precision_dict.items():\n",
    "    print(f\"{name}: {precision:.1f}%\")\n",
    "print(\"=== 데이터셋별 정확도 ===\")\n",
    "for name, accuracy in rag_accuracy.items():\n",
    "    print(f\"{name}: {accuracy:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c423e834",
   "metadata": {},
   "source": [
    "### Astute RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48022436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "making Internal passage (batch):   0%|          | 0/131 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "making Internal passage (batch):  31%|███       | 40/131 [16:56<38:31, 25.40s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m E = make_external_passage()\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# 배치 처리로 Internal passage 생성 (batch_size 조절 가능, GPU 메모리에 따라)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m I = \u001b[43mmake_internal_passage_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m combine_passages = combine_passage(E, I)\n\u001b[32m     29\u001b[39m passage_source = make_passage_source(combine_passages)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/Knowledge-Conflicts/astute_rag.py:43\u001b[39m, in \u001b[36mmake_internal_passage_batch\u001b[39m\u001b[34m(q, P_gen, M, batch_size)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(prompts), batch_size), desc=\u001b[33m\"\u001b[39m\u001b[33mmaking Internal passage (batch)\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     42\u001b[39m     batch_prompts = prompts[i:i+batch_size]\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     batch_answers = \u001b[43mllm_answer_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_prompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m     I.extend(batch_answers)\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m I\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/Knowledge-Conflicts/model.py:87\u001b[39m, in \u001b[36mllm_answer_batch\u001b[39m\u001b[34m(model, tokenizer, prompts, batch_size)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/transformers/generation/utils.py:2566\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2563\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = generation_config.use_cache\n\u001b[32m   2565\u001b[39m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2566\u001b[39m result = \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2568\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2570\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2571\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2572\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2573\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2576\u001b[39m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[32m   2577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2578\u001b[39m     generation_config.return_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2579\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2580\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result.past_key_values, \u001b[33m\"\u001b[39m\u001b[33mto_legacy_cache\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2581\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/transformers/generation/utils.py:2789\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   2787\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2788\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2789\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2791\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   2792\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   2793\u001b[39m     outputs,\n\u001b[32m   2794\u001b[39m     model_kwargs,\n\u001b[32m   2795\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2796\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/transformers/utils/generic.py:918\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    920\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:433\u001b[39m, in \u001b[36mMistralForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[32m    402\u001b[39m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[32m    403\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    414\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    415\u001b[39m ) -> CausalLMOutputWithPast:\n\u001b[32m    416\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[33;03m    Example:\u001b[39;00m\n\u001b[32m    418\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    431\u001b[39m \u001b[33;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[32m    432\u001b[39m \u001b[33;03m    ```\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m     outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m     hidden_states = outputs.last_hidden_state\n\u001b[32m    445\u001b[39m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/transformers/utils/generic.py:1072\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapped_fn.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1069\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m   1071\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1072\u001b[39m     outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[32m   1074\u001b[39m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[32m   1075\u001b[39m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[32m   1076\u001b[39m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[32m   1077\u001b[39m     kwargs_without_recordable = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:369\u001b[39m, in \u001b[36mMistralModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    366\u001b[39m position_embeddings = \u001b[38;5;28mself\u001b[39m.rotary_emb(hidden_states, position_ids)\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers[: \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers]:\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     hidden_states = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.norm(hidden_states)\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[32m    381\u001b[39m     last_hidden_state=hidden_states,\n\u001b[32m    382\u001b[39m     past_key_values=past_key_values \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    383\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:231\u001b[39m, in \u001b[36mMistralDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    229\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    230\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m hidden_states, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    243\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:182\u001b[39m, in \u001b[36mMistralAttention.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings, attention_mask, past_key_values, cache_position, **kwargs)\u001b[39m\n\u001b[32m    169\u001b[39m attn_output, attn_weights = attention_interface(\n\u001b[32m    170\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    171\u001b[39m     query_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m     **kwargs,\n\u001b[32m    179\u001b[39m )\n\u001b[32m    181\u001b[39m attn_output = attn_output.reshape(*input_shape, -\u001b[32m1\u001b[39m).contiguous()\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m attn_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mo_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, attn_weights\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/knowledge_conflict/lib/python3.12/site-packages/bitsandbytes/nn/modules.py:557\u001b[39m, in \u001b[36mLinear4bit.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    554\u001b[39m bias = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias.to(\u001b[38;5;28mself\u001b[39m.compute_dtype)\n\u001b[32m    555\u001b[39m weight = \u001b[38;5;28mself\u001b[39m.weight \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(quant_state, \u001b[33m\"\u001b[39m\u001b[33mpacking_format_for_cpu\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.weight.t()\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbnb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul_4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp_dtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "from astute_rag import (\n",
    "    combine_passage, make_internal_passage, make_external_passage, \n",
    "    make_prompts, make_passage_source, finalize_answer,\n",
    "    make_internal_passage_batch, finalize_answer_batch  # 배치 버전 추가\n",
    ")\n",
    "from prompt_template import P_GEN, P_CON, P_ANS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from acc_prec import load_results, calculate_accuracy_by_dataset_with_astute_rag\n",
    "\n",
    "dataset_sizes = {\n",
    "    \"popqa\": 260,\n",
    "    \"nq\": 260, \n",
    "    \"triviaqa\": 261,\n",
    "    \"bioasq\": 261\n",
    "}\n",
    "\n",
    "with open(\"datasets/total_qa_sampled/qa_dataset.json\", \"r\") as f:\n",
    "    q = json.load(f)\n",
    "\n",
    "P_gen, P_con, P_ans = make_prompts(P_GEN, P_CON, P_ANS)\n",
    "\n",
    "E = make_external_passage()\n",
    "\n",
    "# 배치 처리로 Internal passage 생성 (batch_size 조절 가능, GPU 메모리에 따라)\n",
    "I = make_internal_passage_batch(q, P_gen, llm, batch_size=32)\n",
    "\n",
    "combine_passages = combine_passage(E, I)\n",
    "passage_source = make_passage_source(combine_passages)\n",
    "\n",
    "# 컨텍스트 미리 생성\n",
    "contexts = []\n",
    "questions = []\n",
    "for i in range(len(q)):\n",
    "    context = \"\\n\\n\".join([f\"[{j+1}]\\nsource: {doc['source']}, content: {doc['page_content']}\" for j, doc in enumerate(combine_passages[i])])\n",
    "    contexts.append(context)\n",
    "    questions.append(q[i]['question'])\n",
    "\n",
    "# 배치 처리로 최종 답변 생성\n",
    "finalize_answers = finalize_answer_batch(llm, questions, contexts, batch_size=4)\n",
    "\n",
    "results = load_results('./output/output_with_base_api_rag.jsonl')\n",
    "acc_with_astute_rag = calculate_accuracy_by_dataset_with_astute_rag(results, dataset_sizes, finalize_answers)  \n",
    "acc_with_astute_rag[\"overall\"] = sum(acc_with_astute_rag.values()) / len(acc_with_astute_rag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290acbd2",
   "metadata": {},
   "source": [
    "### 마지막 Astute RAG에 대한 것도 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63368b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Astute RAG 결과 저장 (internal passage 포함)\n",
    "with open(\"./output/output_with_astute_rag_2.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, item in enumerate(results):\n",
    "        result = {\n",
    "            \"question\": item['question'],\n",
    "            \"answers\": finalize_answers[i],  # Astute RAG 최종 답변\n",
    "            \"ground_truth\": item['ground_truth'],\n",
    "            \"docs\": item['docs'],  # external passages\n",
    "            \"internal_passage\": I[i] if i < len(I) else None,  # internal passage\n",
    "            \"baseline_answer\": item['answers']  # baseline RAG 답변 (비교용)\n",
    "        }\n",
    "        f.write(json.dumps(result, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"저장 완료: ./output/output_with_astute_rag_2.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e283f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 데이터셋별 정확도 ===\n",
      "popqa: 58.8%\n",
      "nq: 45.0%\n",
      "triviaqa: 82.0%\n",
      "bioasq: 41.8%\n",
      "overall: 56.9%\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 데이터셋별 정확도 ===\")\n",
    "for name, accuracy in acc_with_astute_rag.items():\n",
    "    print(f\"{name}: {accuracy:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e7c747",
   "metadata": {},
   "source": [
    "### BASELINE RAG 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ef35a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x150 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 준비\n",
    "data = {\n",
    "    'NQ': [0, 0, 0],\n",
    "    'TriviaQA': [0, 0, 0],\n",
    "    'BioASQ': [0, 0, 0],\n",
    "    'PopQA': [0, 0, 0],\n",
    "    'Overall': [0, 0, 0]\n",
    "}\n",
    "\n",
    "# for key in data:\n",
    "#     acc = acc_with_astute_rag[str(key).lower()]\n",
    "#     data[key][2] = round(acc, 1)\n",
    "\n",
    "for key in data:\n",
    "    acc = no_rag_accuracy[str(key).lower()]\n",
    "    data[key][0] = round(acc, 1)\n",
    "    \n",
    "for key in data:\n",
    "    acc = rag_accuracy[str(key).lower()]\n",
    "    data[key][1] = round(acc, 1)  \n",
    "\n",
    "\n",
    "df = pd.DataFrame(data, index=['No RAG', 'Baseline RAG', 'Astute RAG'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 1.5))\n",
    "ax.axis('off')\n",
    "\n",
    "col_labels = [''] + list(df.columns)\n",
    "header_text = [['Mistral-Nemo (2407), 12B', '', '', '', '']]\n",
    "\n",
    "table = ax.table(\n",
    "    cellText=[[idx] + list(row) for idx, row in zip(df.index, df.values)],\n",
    "    colLabels=col_labels,\n",
    "    cellLoc='center',\n",
    "    loc='center'\n",
    ")\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1.2, 1.5)\n",
    "\n",
    "for j in range(len(col_labels)):\n",
    "    table[(0, j)].set_facecolor('#ffffff')\n",
    "    table[(0, j)].set_text_props(fontweight='bold')\n",
    "    table[(0, j)].visible_edges = 'B' \n",
    "\n",
    "for i in range(1, len(df) + 1):\n",
    "    for j in range(len(col_labels)):\n",
    "        table[(i, j)].set_facecolor('#ffffff')\n",
    "        table[(i, j)].visible_edges = 'B' if i < len(df) else ''\n",
    "\n",
    "plt.text(0.5, 0.95, 'Mistral-Nemo (2407), 12B', ha='center', va='bottom', \n",
    "         fontsize=10, fontweight='bold', transform=ax.transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knowledge_conflict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
